{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "141ae67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "from accelerate import Accelerator, notebook_launcher\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import DataCollatorForLanguageModeling, OPTForCausalLM, Trainer, TrainingArguments\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "from utils.save_utils import load_masked_model, load_masked_model_single\n",
    "from utils.prehook_utils import remove_all_hooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52904c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_step():\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    accelerate = Accelerator()\n",
    "    \n",
    "    def encode_tok(examples):\n",
    "        return tokenizer(examples['text'], truncation=True, padding='max_length')\n",
    "\n",
    "\n",
    "    model_name='opt-1.3b'\n",
    "    EPOCH_COUNT=10\n",
    "    SPARSITY=0.2\n",
    "    tokenizer = AutoTokenizer.from_pretrained(f'facebook/{model_name}', padding_side='left')\n",
    "\n",
    "    #stream c4, training split\n",
    "    #training_data = load_dataset('c4', 'en', split='train', streaming=True)\n",
    "    training_data = load_dataset('wikitext', 'wikitext-2-raw-v1', split='train', streaming=True)\n",
    "    #IMPORTANT: process data while streaming -> remove unnecessary columns in batches\n",
    "    training_data = training_data.map(encode_tok, \n",
    "                                      batched=True,\n",
    "                                      remove_columns=[\"text\", \"timestamp\", \"url\"])\n",
    "    #set data to tensor mode\n",
    "    training_data = training_data.with_format(\"torch\")\n",
    "\n",
    "    #dataloader from dataloader (mlm=False when training without mask)\n",
    "    dataloader = DataLoader(training_data, \n",
    "                            collate_fn=DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
    "                            batch_size=1)\n",
    "    #print(torch.cuda.is_initialized())\n",
    "    loaded_model = OPTForCausalLM.from_pretrained(f'facebook/{model_name}',\n",
    "                                                      output_attentions=True,\n",
    "                                                      output_hidden_states=True)\n",
    "    #print(torch.cuda.is_initialized())\n",
    "    if SPARSITY != 1:\n",
    "        load_masked_model_single(loaded_model, f'pruned_models/{model_name}-{SPARSITY}.pt')\n",
    "    #print(torch.cuda.is_initialized())\n",
    "    t_optim = torch.optim.AdamW(params=loaded_model.parameters(), lr=1e-5)\n",
    "\n",
    "\n",
    "    loaded_model, optimizer, training_data = accelerate.prepare(loaded_model, t_optim, dataloader)\n",
    "    !nvidia-smi\n",
    "    loaded_model.train()\n",
    "    t_optim = torch.optim.AdamW(params=loaded_model.parameters(), lr=1e-5)\n",
    "    for epoch in tqdm(range(EPOCH_COUNT)):\n",
    "        #training_data.set_epoch(epoch)\n",
    "        for i, batch in enumerate(dataloader):\n",
    "            print('TRAINING')\n",
    "            !nvidia-smi\n",
    "            #print(batch)\n",
    "            if i == 5:\n",
    "                break\n",
    "            batch = {k: torch.tensor(v) for k, v in batch.items()}\n",
    "            #print(batch)\n",
    "            #print(batch['input_ids'].size())\n",
    "            #print(batch['attention_mask '].size())\n",
    "            outputs = loaded_model(**batch)\n",
    "            loss = outputs.loss\n",
    "            print(loss)\n",
    "            accelerate.backward(loss)\n",
    "            #loss.backward()\n",
    "            t_optim.step()\n",
    "            t_optim.zero_grad()\n",
    "    torch.save(loaded_model.state_dict(), f'pruned_models/{model_name}-{SPARSITY}-finetuned.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16aa0d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching training on 4 GPUs.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭──────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/tmp/ipykernel_14092/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">2085411004.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;cell line: 1&gt;</span>                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: '/tmp/ipykernel_14092/2085411004.py'</span>                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/gs/gsfs0/users/asyed/.local/lib/python3.9/site-packages/accelerate/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">launchers.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">136</span> in   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">notebook_launcher</span>                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">133 │   │   │   │   </span>launcher = PrepareForLaunch(function, distributed_type=<span style=\"color: #808000; text-decoration-color: #808000\">\"MULTI_GPU\"</span>) <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">134 │   │   │   │   </span>                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">135 │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">print</span>(<span style=\"color: #808000; text-decoration-color: #808000\">f\"Launching training on {</span>num_processes<span style=\"color: #808000; text-decoration-color: #808000\">} GPUs.\"</span>)               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>136 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>start_processes(launcher, args=args, nprocs=num_processes, start_me <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">137 │   │   </span>                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">138 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">139 │   │   │   # No need for a distributed launch otherwise as it's either CPU, GPU or</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/gs/gsfs0/users/asyed/.local/lib/python3.9/site-packages/torch/multiprocessing/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">spawn.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">98</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">start_processes</span>                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">195 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> context                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">196 │   </span>                                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">197 │   # Loop on join until it returns True or raises an exception.</span>                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>198 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">while</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> context.join():                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">199 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">pass</span>                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">200 </span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">201 </span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/gs/gsfs0/users/asyed/.local/lib/python3.9/site-packages/torch/multiprocessing/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">spawn.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">60</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">join</span>                                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">157 │   │   </span>original_trace = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.error_queues[error_index].get()                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">158 │   │   </span>msg = <span style=\"color: #808000; text-decoration-color: #808000\">\"\\n\\n-- Process %d terminated with the following error:\\n\"</span> % error_in <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">159 │   │   </span>msg += original_trace                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>160 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> ProcessRaisedException(msg, error_index, failed_process.pid)          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">161 </span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">162 </span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">163 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">class</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; text-decoration: underline\">SpawnContext</span>(ProcessContext):                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰───────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">ProcessRaisedException: </span>\n",
       "\n",
       "-- Process <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> terminated with the following error:\n",
       "Traceback <span style=\"font-weight: bold\">(</span>most recent call last<span style=\"font-weight: bold\">)</span>:\n",
       "  File \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"/gs/gsfs0/users/asyed/.local/lib/python3.9/site-packages/torch/multiprocessing/spawn.py\"</span>, \n",
       "line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">69</span>, in _wrap\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">fn</span><span style=\"font-weight: bold\">(</span>i, *args<span style=\"font-weight: bold\">)</span>\n",
       "  File <span style=\"color: #008000; text-decoration-color: #008000\">\"/gs/gsfs0/users/asyed/.local/lib/python3.9/site-packages/accelerate/utils/launch.py\"</span>,\n",
       "line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">97</span>, in __call__\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">self.launcher</span><span style=\"font-weight: bold\">(</span>*args<span style=\"font-weight: bold\">)</span>\n",
       "  File <span style=\"color: #008000; text-decoration-color: #008000\">\"/tmp/ipykernel_14092/2535096949.py\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>, in training_step\n",
       "    accelerate = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Accelerator</span><span style=\"font-weight: bold\">()</span>\n",
       "  File <span style=\"color: #008000; text-decoration-color: #008000\">\"/gs/gsfs0/users/asyed/.local/lib/python3.9/site-packages/accelerate/accelerator.py\"</span>, \n",
       "line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">323</span>, in __init__\n",
       "    self.state = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AcceleratorState</span><span style=\"font-weight: bold\">(</span>\n",
       "  File <span style=\"color: #008000; text-decoration-color: #008000\">\"/gs/gsfs0/users/asyed/.local/lib/python3.9/site-packages/accelerate/state.py\"</span>, line \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">169</span>, in __init__\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.cuda.set_device</span><span style=\"font-weight: bold\">(</span>self.device<span style=\"font-weight: bold\">)</span>\n",
       "  File <span style=\"color: #008000; text-decoration-color: #008000\">\"/gs/gsfs0/users/asyed/.local/lib/python3.9/site-packages/torch/cuda/__init__.py\"</span>, \n",
       "line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">326</span>, in set_device\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch._C._cuda_setDevice</span><span style=\"font-weight: bold\">(</span>device<span style=\"font-weight: bold\">)</span>\n",
       "  File <span style=\"color: #008000; text-decoration-color: #008000\">\"/gs/gsfs0/users/asyed/.local/lib/python3.9/site-packages/torch/cuda/__init__.py\"</span>, \n",
       "line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">217</span>, in _lazy_init\n",
       "    raise <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RuntimeError</span><span style=\"font-weight: bold\">(</span>\n",
       "RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with \n",
       "multiprocessing, you must use the <span style=\"color: #008000; text-decoration-color: #008000\">'spawn'</span> start method\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m─────────────────────────── \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m ───────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/tmp/ipykernel_14092/\u001b[0m\u001b[1;33m2085411004.py\u001b[0m:\u001b[94m1\u001b[0m in \u001b[92m<cell line: 1>\u001b[0m                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: '/tmp/ipykernel_14092/2085411004.py'\u001b[0m                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/gs/gsfs0/users/asyed/.local/lib/python3.9/site-packages/accelerate/\u001b[0m\u001b[1;33mlaunchers.py\u001b[0m:\u001b[94m136\u001b[0m in   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92mnotebook_launcher\u001b[0m                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m133 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mlauncher = PrepareForLaunch(function, distributed_type=\u001b[33m\"\u001b[0m\u001b[33mMULTI_GPU\u001b[0m\u001b[33m\"\u001b[0m) \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m134 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m135 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[96mprint\u001b[0m(\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mLaunching training on \u001b[0m\u001b[33m{\u001b[0mnum_processes\u001b[33m}\u001b[0m\u001b[33m GPUs.\u001b[0m\u001b[33m\"\u001b[0m)               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m136 \u001b[2m│   │   │   │   \u001b[0mstart_processes(launcher, args=args, nprocs=num_processes, start_me \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m137 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m138 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m139 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# No need for a distributed launch otherwise as it's either CPU, GPU or\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/gs/gsfs0/users/asyed/.local/lib/python3.9/site-packages/torch/multiprocessing/\u001b[0m\u001b[1;33mspawn.py\u001b[0m:\u001b[94m1\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[94m98\u001b[0m in \u001b[92mstart_processes\u001b[0m                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m195 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m context                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m196 \u001b[0m\u001b[2m│   \u001b[0m                                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m197 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# Loop on join until it returns True or raises an exception.\u001b[0m                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m198 \u001b[2m│   \u001b[0m\u001b[94mwhile\u001b[0m \u001b[95mnot\u001b[0m context.join():                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m199 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mpass\u001b[0m                                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m200 \u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m201 \u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/gs/gsfs0/users/asyed/.local/lib/python3.9/site-packages/torch/multiprocessing/\u001b[0m\u001b[1;33mspawn.py\u001b[0m:\u001b[94m1\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[94m60\u001b[0m in \u001b[92mjoin\u001b[0m                                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m157 \u001b[0m\u001b[2m│   │   \u001b[0moriginal_trace = \u001b[96mself\u001b[0m.error_queues[error_index].get()                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m158 \u001b[0m\u001b[2m│   │   \u001b[0mmsg = \u001b[33m\"\u001b[0m\u001b[33m\\n\u001b[0m\u001b[33m\\n\u001b[0m\u001b[33m-- Process \u001b[0m\u001b[33m%d\u001b[0m\u001b[33m terminated with the following error:\u001b[0m\u001b[33m\\n\u001b[0m\u001b[33m\"\u001b[0m % error_in \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m159 \u001b[0m\u001b[2m│   │   \u001b[0mmsg += original_trace                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m160 \u001b[2m│   │   \u001b[0m\u001b[94mraise\u001b[0m ProcessRaisedException(msg, error_index, failed_process.pid)          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m161 \u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m162 \u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m163 \u001b[0m\u001b[94mclass\u001b[0m \u001b[4;92mSpawnContext\u001b[0m(ProcessContext):                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰───────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mProcessRaisedException: \u001b[0m\n",
       "\n",
       "-- Process \u001b[1;36m2\u001b[0m terminated with the following error:\n",
       "Traceback \u001b[1m(\u001b[0mmost recent call last\u001b[1m)\u001b[0m:\n",
       "  File \n",
       "\u001b[32m\"/gs/gsfs0/users/asyed/.local/lib/python3.9/site-packages/torch/multiprocessing/spawn.py\"\u001b[0m, \n",
       "line \u001b[1;36m69\u001b[0m, in _wrap\n",
       "    \u001b[1;35mfn\u001b[0m\u001b[1m(\u001b[0mi, *args\u001b[1m)\u001b[0m\n",
       "  File \u001b[32m\"/gs/gsfs0/users/asyed/.local/lib/python3.9/site-packages/accelerate/utils/launch.py\"\u001b[0m,\n",
       "line \u001b[1;36m97\u001b[0m, in __call__\n",
       "    \u001b[1;35mself.launcher\u001b[0m\u001b[1m(\u001b[0m*args\u001b[1m)\u001b[0m\n",
       "  File \u001b[32m\"/tmp/ipykernel_14092/2535096949.py\"\u001b[0m, line \u001b[1;36m3\u001b[0m, in training_step\n",
       "    accelerate = \u001b[1;35mAccelerator\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
       "  File \u001b[32m\"/gs/gsfs0/users/asyed/.local/lib/python3.9/site-packages/accelerate/accelerator.py\"\u001b[0m, \n",
       "line \u001b[1;36m323\u001b[0m, in __init__\n",
       "    self.state = \u001b[1;35mAcceleratorState\u001b[0m\u001b[1m(\u001b[0m\n",
       "  File \u001b[32m\"/gs/gsfs0/users/asyed/.local/lib/python3.9/site-packages/accelerate/state.py\"\u001b[0m, line \n",
       "\u001b[1;36m169\u001b[0m, in __init__\n",
       "    \u001b[1;35mtorch.cuda.set_device\u001b[0m\u001b[1m(\u001b[0mself.device\u001b[1m)\u001b[0m\n",
       "  File \u001b[32m\"/gs/gsfs0/users/asyed/.local/lib/python3.9/site-packages/torch/cuda/__init__.py\"\u001b[0m, \n",
       "line \u001b[1;36m326\u001b[0m, in set_device\n",
       "    \u001b[1;35mtorch._C._cuda_setDevice\u001b[0m\u001b[1m(\u001b[0mdevice\u001b[1m)\u001b[0m\n",
       "  File \u001b[32m\"/gs/gsfs0/users/asyed/.local/lib/python3.9/site-packages/torch/cuda/__init__.py\"\u001b[0m, \n",
       "line \u001b[1;36m217\u001b[0m, in _lazy_init\n",
       "    raise \u001b[1;35mRuntimeError\u001b[0m\u001b[1m(\u001b[0m\n",
       "RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with \n",
       "multiprocessing, you must use the \u001b[32m'spawn'\u001b[0m start method\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "notebook_launcher(training_step, args=(), num_processes=4, mixed_precision='bf16')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34886d5a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
