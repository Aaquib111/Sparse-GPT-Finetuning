{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.utils import prune\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from transformers import AutoTokenizer, OPTForCausalLM, pipeline\n",
    "from datasets import load_dataset\n",
    "\n",
    "from calculate_mask import calculate_mask\n",
    "from inverse_hessian import calc_inverse_hessian\n",
    "from input_prehooks import put_input_hooks\n",
    "from testing_module import calculate_perp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEVICE\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model_name = \"facebook/opt-350m\"\n",
    "# model_name = \"facebook/opt-1.3b\"\n",
    "\n",
    "#Load dataset\n",
    "dataset = load_dataset('c4', 'en', streaming=True)\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, padding_side='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calibrate model (get inputs to each layer with calibration data)\n",
    "\n",
    "calibration_size=4\n",
    "token_length=512\n",
    "calibration_batch_size=2\n",
    "\n",
    "EPSILON = 1e-8\n",
    "B = 4\n",
    "Bs = 2\n",
    "\n",
    "# run model on batches of calibration data, then concatenate inputs\n",
    "def split_model_calibration(model):\n",
    "    batch_sentences = []\n",
    "    for i, data in tqdm(enumerate(iter(dataset['train'])), total=calibration_size):\n",
    "        if i < calibration_size + 1:\n",
    "            if len(batch_sentences) >= calibration_batch_size:\n",
    "                with torch.no_grad():\n",
    "                    encoded_input = tokenizer(batch_sentences, return_tensors=\"pt\",\n",
    "                                              padding=\"max_length\", max_length=token_length,\n",
    "                                              truncation=True).to(device=device)\n",
    "                    model(**encoded_input, labels=encoded_input.input_ids)\n",
    "                    batch_sentences = []\n",
    "            batch_sentences.append(data['text'])\n",
    "        else:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparsify Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get module name from parameter name\n",
    "def get_module_name(param_name):\n",
    "    if param_name[-5:] == \".bias\":\n",
    "        return param_name[:-5], \"bias\"\n",
    "    elif param_name[-7:] == \".weight\":\n",
    "        return param_name[:-7], \"weight\"\n",
    "    else:\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:03,  1.43it/s]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 388/388 [00:56<00:00,  6.82it/s]\n"
     ]
    }
   ],
   "source": [
    "from input_prehooks import get_feature_storage_name\n",
    "import gc\n",
    "layer_blacklist = ['model.decoder.embed_tokens.weight', 'model.decoder.embed_tokens.bias', 'model.decoder.embed_positions.weight']\n",
    "\n",
    "# Using calibration data (inputs to each intermediate weight layer)\n",
    "# Iterate through named parameters, calculate inverse hessian and calculate mask\n",
    "\n",
    "SPARSENESS_LIST = [0.5]#0.1, 0.2, 0.3, 0.5, 0.7, 0.9\n",
    "for i, SPARSENESS in enumerate(SPARSENESS_LIST):\n",
    "    \n",
    "    # Load model with pre-trained head\n",
    "    model = OPTForCausalLM.from_pretrained(model_name, output_attentions=True,\n",
    "                                           output_hidden_states=True).to(device=device) # type: ignore\n",
    "    \n",
    "    #storage_dir = f'tmp/{model_name}-{SPARSENESS}'\n",
    "    \n",
    "    # First, put in forward hooks\n",
    "    # Don't store inputs, instead store hessians (less data)\n",
    "    # Only store hessians once, as all models take the same hessians\n",
    "    print('------------')\n",
    "    if i == 0:\n",
    "        feature_hessians = {}\n",
    "        #put_input_hooks(model=model, features=feature_hessians, storage_dir=storage_dir, offload_freq=10000, feature_storage_device='cpu')\n",
    "        put_input_hooks(model=model, features=feature_hessians, feature_storage_device='cpu')\n",
    "        split_model_calibration(model)\n",
    "        torch.cuda.empty_cache()\n",
    "    print('-----------')\n",
    "    # make a dictionary to access module by name\n",
    "    module_lookup_dict = {}\n",
    "    for module_name, module_iter in model.named_modules():\n",
    "        module_lookup_dict[module_name] = module_iter\n",
    "\n",
    "    # without this\n",
    "    param_lookup_dict = {}\n",
    "    param_names = []\n",
    "    for name, param in model.named_parameters():\n",
    "        param_names.append(name)\n",
    "        param_lookup_dict[name] = param\n",
    "    \n",
    "    model.eval()\n",
    "    model = torch.nn.DataParallel(model, device_ids=[0,1,2,3])\n",
    "    with torch.no_grad():\n",
    "        # for name in tqdm(param_names):\n",
    "        for name in tqdm(param_names, total=len(param_names)):\n",
    "            param = param_lookup_dict[name]\n",
    "\n",
    "            # skip the embed layer\n",
    "            if name in layer_blacklist:\n",
    "                continue\n",
    "            # skip norms which have 1 dimension\n",
    "            if len(param.shape) < 2:\n",
    "                continue\n",
    "\n",
    "            module_name, param_type = get_module_name(name)\n",
    "\n",
    "            # apply to weight layers\n",
    "            if param_type == \"weight\":\n",
    "                #print(f\"Doing layer {name}\")\n",
    "                # get layer input from features, key is get_feature_storage_name(module_name)\n",
    "                # get_feature_storage_name(module_name) stores k_proj, v_proj, q_proj together\n",
    "                # since they are the same input\n",
    "                \n",
    "                layer_hessian = feature_hessians[get_feature_storage_name(module_name)].to(device=device)\n",
    "\n",
    "                # calculate inverse hessian\n",
    "                # check if input is flattened e.g. from 8,512,768 to 4096,768\n",
    "                inv_hess = calc_inverse_hessian(layer_hessian, epsilon=EPSILON)\n",
    "\n",
    "                # calculate mask\n",
    "                mask = calculate_mask(W=param, H_inv=inv_hess, p=SPARSENESS, B=B, Bs=Bs)\n",
    "\n",
    "                # get module from lookup dictionary by module name\n",
    "                module = module_lookup_dict[module_name]\n",
    "                # apply mask\n",
    "                prune.custom_from_mask(module=module, name=param_type, mask=mask)\n",
    "                prune.remove(module=module, name=param_type)\n",
    "                gc.collect()\n",
    "                torch.cuda.empty_cache()           \n",
    "    pruned_model_name = f'opt-350m-test-{SPARSENESS}'\n",
    "\n",
    "    torch.save(model.state_dict(), f'pruned_models/{pruned_model_name}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 388/388 [00:00<00:00, 14464.66it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for DataParallel:\n\tMissing key(s) in state_dict: \"module.model.decoder.project_out.weight_orig\", \"module.model.decoder.project_out.weight_mask\", \"module.model.decoder.project_in.weight_orig\", \"module.model.decoder.project_in.weight_mask\", \"module.model.decoder.layers.0.self_attn.k_proj.weight_orig\", \"module.model.decoder.layers.0.self_attn.k_proj.weight_mask\", \"module.model.decoder.layers.0.self_attn.v_proj.weight_orig\", \"module.model.decoder.layers.0.self_attn.v_proj.weight_mask\", \"module.model.decoder.layers.0.self_attn.q_proj.weight_orig\", \"module.model.decoder.layers.0.self_attn.q_proj.weight_mask\", \"module.model.decoder.layers.0.self_attn.out_proj.weight_orig\", \"module.model.decoder.layers.0.self_attn.out_proj.weight_mask\", \"module.model.decoder.layers.0.fc1.weight_orig\", \"module.model.decoder.layers.0.fc1.weight_mask\", \"module.model.decoder.layers.0.fc2.weight_orig\", \"module.model.decoder.layers.0.fc2.weight_mask\", \"module.model.decoder.layers.1.self_attn.k_proj.weight_orig\", \"module.model.decoder.layers.1.self_attn.k_proj.weight_mask\", \"module.model.decoder.layers.1.self_attn.v_proj.weight_orig\", \"module.model.decoder.layers.1.self_attn.v_proj.weight_mask\", \"module.model.decoder.layers.1.self_attn.q_proj.weight_orig\", \"module.model.decoder.layers.1.self_attn.q_proj.weight_mask\", \"module.model.decoder.layers.1.self_attn.out_proj.weight_orig\", \"module.model.decoder.layers.1.self_attn.out_proj.weight_mask\", \"module.model.decoder.layers.1.fc1.weight_orig\", \"module.model.decoder.layers.1.fc1.weight_mask\", \"module.model.decoder.layers.1.fc2.weight_orig\", \"module.model.decoder.layers.1.fc2.weight_mask\", \"module.model.decoder.layers.2.self_attn.k_proj.weight_orig\", \"module.model.decoder.layers.2.self_attn.k_proj.weight_mask\", \"module.model.decoder.layers.2.self_attn.v_proj.weight_orig\", \"module.model.decoder.layers.2.self_attn.v_proj.weight_mask\", \"module.model.decoder.layers.2.self_attn.q_proj.weight_orig\", \"module.model.decoder.layers.2.self_attn.q_proj.weight_mask\", \"module.model.decoder.layers.2.self_attn.out_proj.weight_orig\", \"module.model.decoder.layers.2.self_attn.out_proj.weight_mask\", \"module.model.decoder.layers.2.fc1.weight_orig\", \"module.model.decoder.layers.2.fc1.weight_mask\", \"module.model.decoder.layers.2.fc2.weight_orig\", \"module.model.decoder.layers.2.fc2.weight_mask\", \"module.model.decoder.layers.3.self_attn.k_proj.weight_orig\", \"module.model.decoder.layers.3.self_attn.k_proj.weight_mask\", \"module.model.decoder.layers.3.self_attn.v_proj.weight_orig\", \"module.model.decoder.layers.3.self_attn.v_proj.weight_mask\", \"module.model.decoder.layers.3.self_attn.q_proj.weight_orig\", \"module.model.decoder.layers.3.self_attn.q_proj.weight_mask\", \"module.model.decoder.layers.3.self_attn.out_proj.weight_orig\", \"module.model.decoder.layers.3.self_attn.out_proj.weight_mask\", \"module.model.decoder.layers.3.fc1.weight_orig\", \"module.model.decoder.layers.3.fc1.weight_mask\", \"module.model.decoder.layers.3.fc2.weight_orig\", \"module.model.decoder.layers.3.fc2.weight_mask\", \"module.model.decoder.layers.4.self_attn.k_proj.weight_orig\", \"module.model.decoder.layers.4.self_attn.k_proj.weight_mask\", \"module.model.decoder.layers.4.self_attn.v_proj.weight_orig\", \"module.model.decoder.layers.4.self_attn.v_proj.weight_mask\", \"module.model.decoder.layers.4.self_attn.q_proj.weight_orig\", \"module.model.decoder.layers.4.self_attn.q_proj.weight_mask\", \"module.model.decoder.layers.4.self_attn.out_proj.weight_orig\", \"module.model.decoder.layers.4.self_attn.out_proj.weight_mask\", \"module.model.decoder.layers.4.fc1.weight_orig\", \"module.model.decoder.layers.4.fc1.weight_mask\", \"module.model.decoder.layers.4.fc2.weight_orig\", \"module.model.decoder.layers.4.fc2.weight_mask\", \"module.model.decoder.layers.5.self_attn.k_proj.weight_orig\", \"module.model.decoder.layers.5.self_attn.k_proj.weight_mask\", \"module.model.decoder.layers.5.self_attn.v_proj.weight_orig\", \"module.model.decoder.layers.5.self_attn.v_proj.weight_mask\", \"module.model.decoder.layers.5.self_attn.q_proj.weight_orig\", \"module.model.decoder.layers.5.self_attn.q_proj.weight_mask\", \"module.model.decoder.layers.5.self_attn.out_proj.weight_orig\", \"module.model.decoder.layers.5.self_attn.out_proj.weight_mask\", \"module.model.decoder.layers.5.fc1.weight_orig\", \"module.model.decoder.layers.5.fc1.weight_mask\", \"module.model.decoder.layers.5.fc2.weight_orig\", \"module.model.decoder.layers.5.fc2.weight_mask\", \"module.model.decoder.layers.6.self_attn.k_proj.weight_orig\", \"module.model.decoder.layers.6.self_attn.k_proj.weight_mask\", \"module.model.decoder.layers.6.self_attn.v_proj.weight_orig\", \"module.model.decoder.layers.6.self_attn.v_proj.weight_mask\", \"module.model.decoder.layers.6.self_attn.q_proj.weight_orig\", \"module.model.decoder.layers.6.self_attn.q_proj.weight_mask\", \"module.model.decoder.layers.6.self_attn.out_proj.weight_orig\", \"module.model.decoder.layers.6.self_attn.out_proj.weight_mask\", \"module.model.decoder.layers.6.fc1.weight_orig\", \"module.model.decoder.layers.6.fc1.weight_mask\", \"module.model.decoder.layers.6.fc2.weight_orig\", \"module.model.decoder.layers.6.fc2.weight_mask\", \"module.model.decoder.layers.7.self_attn.k_proj.weight_orig\", \"module.model.decoder.layers.7.self_attn.k_proj.weight_mask\", \"module.model.decoder.layers.7.self_attn.v_proj.weight_orig\", \"module.model.decoder.layers.7.self_attn.v_proj.weight_mask\", \"module.model.decoder.layers.7.self_attn.q_proj.weight_orig\", \"module.model.decoder.layers.7.self_attn.q_proj.weight_mask\", \"module.model.decoder.layers.7.self_attn.out_proj.weight_orig\", \"module.model.decoder.layers.7.self_attn.out_proj.weight_mask\", \"module.model.decoder.layers.7.fc1.weight_orig\", \"module.model.decoder.layers.7.fc1.weight_mask\", \"module.model.decoder.layers.7.fc2.weight_orig\", \"module.model.decoder.layers.7.fc2.weight_mask\", \"module.model.decoder.layers.8.self_attn.k_proj.weight_orig\", \"module.model.decoder.layers.8.self_attn.k_proj.weight_mask\", \"module.model.decoder.layers.8.self_attn.v_proj.weight_orig\", \"module.model.decoder.layers.8.self_attn.v_proj.weight_mask\", \"module.model.decoder.layers.8.self_attn.q_proj.weight_orig\", \"module.model.decoder.layers.8.self_attn.q_proj.weight_mask\", \"module.model.decoder.layers.8.self_attn.out_proj.weight_orig\", \"module.model.decoder.layers.8.self_attn.out_proj.weight_mask\", \"module.model.decoder.layers.8.fc1.weight_orig\", \"module.model.decoder.layers.8.fc1.weight_mask\", \"module.model.decoder.layers.8.fc2.weight_orig\", \"module.model.decoder.layers.8.fc2.weight_mask\", \"module.model.decoder.layers.9.self_attn.k_proj.weight_orig\", \"module.model.decoder.layers.9.self_attn.k_proj.weight_mask\", \"module.model.decoder.layers.9.self_attn.v_proj.weight_orig\", \"module.model.decoder.layers.9.self_attn.v_proj.weight_mask\", \"module.model.decoder.layers.9.self_attn.q_proj.weight_orig\", \"module.model.decoder.layers.9.self_attn.q_proj.weight_mask\", \"module.model.decoder.layers.9.self_attn.out_proj.weight_orig\", \"module.model.decoder.layers.9.self_attn.out_proj.weight_mask\", \"module.model.decoder.layers.9.fc1.weight_orig\", \"module.model.decoder.layers.9.fc1.weight_mask\", \"module.model.decoder.layers.9.fc2.weight_orig\", \"module.model.decoder.layers.9.fc2.weight_mask\", \"module.model.decoder.layers.10.self_attn.k_proj.weight_orig\", \"module.model.decoder.layers.10.self_attn.k_proj.weight_mask\", \"module.model.decoder.layers.10.self_attn.v_proj.weight_orig\", \"module.model.decoder.layers.10.self_attn.v_proj.weight_mask\", \"module.model.decoder.layers.10.self_attn.q_proj.weight_orig\", \"module.model.decoder.layers.10.self_attn.q_proj.weight_mask\", \"module.model.decoder.layers.10.self_attn.out_proj.weight_orig\", \"module.model.decoder.layers.10.self_attn.out_proj.weight_mask\", \"module.model.decoder.layers.10.fc1.weight_orig\", \"module.model.decoder.layers.10.fc1.weight_mask\", \"module.model.decoder.layers.10.fc2.weight_orig\", \"module.model.decoder.layers.10.fc2.weight_mask\", \"module.model.decoder.layers.11.self_attn.k_proj.weight_orig\", \"module.model.decoder.layers.11.self_attn.k_proj.weight_mask\", \"module.model.decoder.layers.11.self_attn.v_proj.weight_orig\", \"module.model.decoder.layers.11.self_attn.v_proj.weight_mask\", \"module.model.decoder.layers.11.self_attn.q_proj.weight_orig\", \"module.model.decoder.layers.11.self_attn.q_proj.weight_mask\", \"module.model.decoder.layers.11.self_attn.out_proj.weight_orig\", \"module.model.decoder.layers.11.self_attn.out_proj.weight_mask\", \"module.model.decoder.layers.11.fc1.weight_orig\", \"module.model.decoder.layers.11.fc1.weight_mask\", \"module.model.decoder.layers.11.fc2.weight_orig\", \"module.model.decoder.layers.11.fc2.weight_mask\", \"module.model.decoder.layers.12.self_attn.k_proj.weight_orig\", \"module.model.decoder.layers.12.self_attn.k_proj.weight_mask\", \"module.model.decoder.layers.12.self_attn.v_proj.weight_orig\", \"module.model.decoder.layers.12.self_attn.v_proj.weight_mask\", \"module.model.decoder.layers.12.self_attn.q_proj.weight_orig\", \"module.model.decoder.layers.12.self_attn.q_proj.weight_mask\", \"module.model.decoder.layers.12.self_attn.out_proj.weight_orig\", \"module.model.decoder.layers.12.self_attn.out_proj.weight_mask\", \"module.model.decoder.layers.12.fc1.weight_orig\", \"module.model.decoder.layers.12.fc1.weight_mask\", \"module.model.decoder.layers.12.fc2.weight_orig\", \"module.model.decoder.layers.12.fc2.weight_mask\", \"module.model.decoder.layers.13.self_attn.k_proj.weight_orig\", \"module.model.decoder.layers.13.self_attn.k_proj.weight_mask\", \"module.model.decoder.layers.13.self_attn.v_proj.weight_orig\", \"module.model.decoder.layers.13.self_attn.v_proj.weight_mask\", \"module.model.decoder.layers.13.self_attn.q_proj.weight_orig\", \"module.model.decoder.layers.13.self_attn.q_proj.weight_mask\", \"module.model.decoder.layers.13.self_attn.out_proj.weight_orig\", \"module.model.decoder.layers.13.self_attn.out_proj.weight_mask\", \"module.model.decoder.layers.13.fc1.weight_orig\", \"module.model.decoder.layers.13.fc1.weight_mask\", \"module.model.decoder.layers.13.fc2.weight_orig\", \"module.model.decoder.layers.13.fc2.weight_mask\", \"module.model.decoder.layers.14.self_attn.k_proj.weight_orig\", \"module.model.decoder.layers.14.self_attn.k_proj.weight_mask\", \"module.model.decoder.layers.14.self_attn.v_proj.weight_orig\", \"module.model.decoder.layers.14.self_attn.v_proj.weight_mask\", \"module.model.decoder.layers.14.self_attn.q_proj.weight_orig\", \"module.model.decoder.layers.14.self_attn.q_proj.weight_mask\", \"module.model.decoder.layers.14.self_attn.out_proj.weight_orig\", \"module.model.decoder.layers.14.self_attn.out_proj.weight_mask\", \"module.model.decoder.layers.14.fc1.weight_orig\", \"module.model.decoder.layers.14.fc1.weight_mask\", \"module.model.decoder.layers.14.fc2.weight_orig\", \"module.model.decoder.layers.14.fc2.weight_mask\", \"module.model.decoder.layers.15.self_attn.k_proj.weight_orig\", \"module.model.decoder.layers.15.self_attn.k_proj.weight_mask\", \"module.model.decoder.layers.15.self_attn.v_proj.weight_orig\", \"module.model.decoder.layers.15.self_attn.v_proj.weight_mask\", \"module.model.decoder.layers.15.self_attn.q_proj.weight_orig\", \"module.model.decoder.layers.15.self_attn.q_proj.weight_mask\", \"module.model.decoder.layers.15.self_attn.out_proj.weight_orig\", \"module.model.decoder.layers.15.self_attn.out_proj.weight_mask\", \"module.model.decoder.layers.15.fc1.weight_orig\", \"module.model.decoder.layers.15.fc1.weight_mask\", \"module.model.decoder.layers.15.fc2.weight_orig\", \"module.model.decoder.layers.15.fc2.weight_mask\", \"module.model.decoder.layers.16.self_attn.k_proj.weight_orig\", \"module.model.decoder.layers.16.self_attn.k_proj.weight_mask\", \"module.model.decoder.layers.16.self_attn.v_proj.weight_orig\", \"module.model.decoder.layers.16.self_attn.v_proj.weight_mask\", \"module.model.decoder.layers.16.self_attn.q_proj.weight_orig\", \"module.model.decoder.layers.16.self_attn.q_proj.weight_mask\", \"module.model.decoder.layers.16.self_attn.out_proj.weight_orig\", \"module.model.decoder.layers.16.self_attn.out_proj.weight_mask\", \"module.model.decoder.layers.16.fc1.weight_orig\", \"module.model.decoder.layers.16.fc1.weight_mask\", \"module.model.decoder.layers.16.fc2.weight_orig\", \"module.model.decoder.layers.16.fc2.weight_mask\", \"module.model.decoder.layers.17.self_attn.k_proj.weight_orig\", \"module.model.decoder.layers.17.self_attn.k_proj.weight_mask\", \"module.model.decoder.layers.17.self_attn.v_proj.weight_orig\", \"module.model.decoder.layers.17.self_attn.v_proj.weight_mask\", \"module.model.decoder.layers.17.self_attn.q_proj.weight_orig\", \"module.model.decoder.layers.17.self_attn.q_proj.weight_mask\", \"module.model.decoder.layers.17.self_attn.out_proj.weight_orig\", \"module.model.decoder.layers.17.self_attn.out_proj.weight_mask\", \"module.model.decoder.layers.17.fc1.weight_orig\", \"module.model.decoder.layers.17.fc1.weight_mask\", \"module.model.decoder.layers.17.fc2.weight_orig\", \"module.model.decoder.layers.17.fc2.weight_mask\", \"module.model.decoder.layers.18.self_attn.k_proj.weight_orig\", \"module.model.decoder.layers.18.self_attn.k_proj.weight_mask\", \"module.model.decoder.layers.18.self_attn.v_proj.weight_orig\", \"module.model.decoder.layers.18.self_attn.v_proj.weight_mask\", \"module.model.decoder.layers.18.self_attn.q_proj.weight_orig\", \"module.model.decoder.layers.18.self_attn.q_proj.weight_mask\", \"module.model.decoder.layers.18.self_attn.out_proj.weight_orig\", \"module.model.decoder.layers.18.self_attn.out_proj.weight_mask\", \"module.model.decoder.layers.18.fc1.weight_orig\", \"module.model.decoder.layers.18.fc1.weight_mask\", \"module.model.decoder.layers.18.fc2.weight_orig\", \"module.model.decoder.layers.18.fc2.weight_mask\", \"module.model.decoder.layers.19.self_attn.k_proj.weight_orig\", \"module.model.decoder.layers.19.self_attn.k_proj.weight_mask\", \"module.model.decoder.layers.19.self_attn.v_proj.weight_orig\", \"module.model.decoder.layers.19.self_attn.v_proj.weight_mask\", \"module.model.decoder.layers.19.self_attn.q_proj.weight_orig\", \"module.model.decoder.layers.19.self_attn.q_proj.weight_mask\", \"module.model.decoder.layers.19.self_attn.out_proj.weight_orig\", \"module.model.decoder.layers.19.self_attn.out_proj.weight_mask\", \"module.model.decoder.layers.19.fc1.weight_orig\", \"module.model.decoder.layers.19.fc1.weight_mask\", \"module.model.decoder.layers.19.fc2.weight_orig\", \"module.model.decoder.layers.19.fc2.weight_mask\", \"module.model.decoder.layers.20.self_attn.k_proj.weight_orig\", \"module.model.decoder.layers.20.self_attn.k_proj.weight_mask\", \"module.model.decoder.layers.20.self_attn.v_proj.weight_orig\", \"module.model.decoder.layers.20.self_attn.v_proj.weight_mask\", \"module.model.decoder.layers.20.self_attn.q_proj.weight_orig\", \"module.model.decoder.layers.20.self_attn.q_proj.weight_mask\", \"module.model.decoder.layers.20.self_attn.out_proj.weight_orig\", \"module.model.decoder.layers.20.self_attn.out_proj.weight_mask\", \"module.model.decoder.layers.20.fc1.weight_orig\", \"module.model.decoder.layers.20.fc1.weight_mask\", \"module.model.decoder.layers.20.fc2.weight_orig\", \"module.model.decoder.layers.20.fc2.weight_mask\", \"module.model.decoder.layers.21.self_attn.k_proj.weight_orig\", \"module.model.decoder.layers.21.self_attn.k_proj.weight_mask\", \"module.model.decoder.layers.21.self_attn.v_proj.weight_orig\", \"module.model.decoder.layers.21.self_attn.v_proj.weight_mask\", \"module.model.decoder.layers.21.self_attn.q_proj.weight_orig\", \"module.model.decoder.layers.21.self_attn.q_proj.weight_mask\", \"module.model.decoder.layers.21.self_attn.out_proj.weight_orig\", \"module.model.decoder.layers.21.self_attn.out_proj.weight_mask\", \"module.model.decoder.layers.21.fc1.weight_orig\", \"module.model.decoder.layers.21.fc1.weight_mask\", \"module.model.decoder.layers.21.fc2.weight_orig\", \"module.model.decoder.layers.21.fc2.weight_mask\", \"module.model.decoder.layers.22.self_attn.k_proj.weight_orig\", \"module.model.decoder.layers.22.self_attn.k_proj.weight_mask\", \"module.model.decoder.layers.22.self_attn.v_proj.weight_orig\", \"module.model.decoder.layers.22.self_attn.v_proj.weight_mask\", \"module.model.decoder.layers.22.self_attn.q_proj.weight_orig\", \"module.model.decoder.layers.22.self_attn.q_proj.weight_mask\", \"module.model.decoder.layers.22.self_attn.out_proj.weight_orig\", \"module.model.decoder.layers.22.self_attn.out_proj.weight_mask\", \"module.model.decoder.layers.22.fc1.weight_orig\", \"module.model.decoder.layers.22.fc1.weight_mask\", \"module.model.decoder.layers.22.fc2.weight_orig\", \"module.model.decoder.layers.22.fc2.weight_mask\", \"module.model.decoder.layers.23.self_attn.k_proj.weight_orig\", \"module.model.decoder.layers.23.self_attn.k_proj.weight_mask\", \"module.model.decoder.layers.23.self_attn.v_proj.weight_orig\", \"module.model.decoder.layers.23.self_attn.v_proj.weight_mask\", \"module.model.decoder.layers.23.self_attn.q_proj.weight_orig\", \"module.model.decoder.layers.23.self_attn.q_proj.weight_mask\", \"module.model.decoder.layers.23.self_attn.out_proj.weight_orig\", \"module.model.decoder.layers.23.self_attn.out_proj.weight_mask\", \"module.model.decoder.layers.23.fc1.weight_orig\", \"module.model.decoder.layers.23.fc1.weight_mask\", \"module.model.decoder.layers.23.fc2.weight_orig\", \"module.model.decoder.layers.23.fc2.weight_mask\". \n\tUnexpected key(s) in state_dict: \"module.model.decoder.project_out.weight\", \"module.model.decoder.project_in.weight\", \"module.model.decoder.layers.0.self_attn.k_proj.weight\", \"module.model.decoder.layers.0.self_attn.v_proj.weight\", \"module.model.decoder.layers.0.self_attn.q_proj.weight\", \"module.model.decoder.layers.0.self_attn.out_proj.weight\", \"module.model.decoder.layers.0.fc1.weight\", \"module.model.decoder.layers.0.fc2.weight\", \"module.model.decoder.layers.1.self_attn.k_proj.weight\", \"module.model.decoder.layers.1.self_attn.v_proj.weight\", \"module.model.decoder.layers.1.self_attn.q_proj.weight\", \"module.model.decoder.layers.1.self_attn.out_proj.weight\", \"module.model.decoder.layers.1.fc1.weight\", \"module.model.decoder.layers.1.fc2.weight\", \"module.model.decoder.layers.2.self_attn.k_proj.weight\", \"module.model.decoder.layers.2.self_attn.v_proj.weight\", \"module.model.decoder.layers.2.self_attn.q_proj.weight\", \"module.model.decoder.layers.2.self_attn.out_proj.weight\", \"module.model.decoder.layers.2.fc1.weight\", \"module.model.decoder.layers.2.fc2.weight\", \"module.model.decoder.layers.3.self_attn.k_proj.weight\", \"module.model.decoder.layers.3.self_attn.v_proj.weight\", \"module.model.decoder.layers.3.self_attn.q_proj.weight\", \"module.model.decoder.layers.3.self_attn.out_proj.weight\", \"module.model.decoder.layers.3.fc1.weight\", \"module.model.decoder.layers.3.fc2.weight\", \"module.model.decoder.layers.4.self_attn.k_proj.weight\", \"module.model.decoder.layers.4.self_attn.v_proj.weight\", \"module.model.decoder.layers.4.self_attn.q_proj.weight\", \"module.model.decoder.layers.4.self_attn.out_proj.weight\", \"module.model.decoder.layers.4.fc1.weight\", \"module.model.decoder.layers.4.fc2.weight\", \"module.model.decoder.layers.5.self_attn.k_proj.weight\", \"module.model.decoder.layers.5.self_attn.v_proj.weight\", \"module.model.decoder.layers.5.self_attn.q_proj.weight\", \"module.model.decoder.layers.5.self_attn.out_proj.weight\", \"module.model.decoder.layers.5.fc1.weight\", \"module.model.decoder.layers.5.fc2.weight\", \"module.model.decoder.layers.6.self_attn.k_proj.weight\", \"module.model.decoder.layers.6.self_attn.v_proj.weight\", \"module.model.decoder.layers.6.self_attn.q_proj.weight\", \"module.model.decoder.layers.6.self_attn.out_proj.weight\", \"module.model.decoder.layers.6.fc1.weight\", \"module.model.decoder.layers.6.fc2.weight\", \"module.model.decoder.layers.7.self_attn.k_proj.weight\", \"module.model.decoder.layers.7.self_attn.v_proj.weight\", \"module.model.decoder.layers.7.self_attn.q_proj.weight\", \"module.model.decoder.layers.7.self_attn.out_proj.weight\", \"module.model.decoder.layers.7.fc1.weight\", \"module.model.decoder.layers.7.fc2.weight\", \"module.model.decoder.layers.8.self_attn.k_proj.weight\", \"module.model.decoder.layers.8.self_attn.v_proj.weight\", \"module.model.decoder.layers.8.self_attn.q_proj.weight\", \"module.model.decoder.layers.8.self_attn.out_proj.weight\", \"module.model.decoder.layers.8.fc1.weight\", \"module.model.decoder.layers.8.fc2.weight\", \"module.model.decoder.layers.9.self_attn.k_proj.weight\", \"module.model.decoder.layers.9.self_attn.v_proj.weight\", \"module.model.decoder.layers.9.self_attn.q_proj.weight\", \"module.model.decoder.layers.9.self_attn.out_proj.weight\", \"module.model.decoder.layers.9.fc1.weight\", \"module.model.decoder.layers.9.fc2.weight\", \"module.model.decoder.layers.10.self_attn.k_proj.weight\", \"module.model.decoder.layers.10.self_attn.v_proj.weight\", \"module.model.decoder.layers.10.self_attn.q_proj.weight\", \"module.model.decoder.layers.10.self_attn.out_proj.weight\", \"module.model.decoder.layers.10.fc1.weight\", \"module.model.decoder.layers.10.fc2.weight\", \"module.model.decoder.layers.11.self_attn.k_proj.weight\", \"module.model.decoder.layers.11.self_attn.v_proj.weight\", \"module.model.decoder.layers.11.self_attn.q_proj.weight\", \"module.model.decoder.layers.11.self_attn.out_proj.weight\", \"module.model.decoder.layers.11.fc1.weight\", \"module.model.decoder.layers.11.fc2.weight\", \"module.model.decoder.layers.12.self_attn.k_proj.weight\", \"module.model.decoder.layers.12.self_attn.v_proj.weight\", \"module.model.decoder.layers.12.self_attn.q_proj.weight\", \"module.model.decoder.layers.12.self_attn.out_proj.weight\", \"module.model.decoder.layers.12.fc1.weight\", \"module.model.decoder.layers.12.fc2.weight\", \"module.model.decoder.layers.13.self_attn.k_proj.weight\", \"module.model.decoder.layers.13.self_attn.v_proj.weight\", \"module.model.decoder.layers.13.self_attn.q_proj.weight\", \"module.model.decoder.layers.13.self_attn.out_proj.weight\", \"module.model.decoder.layers.13.fc1.weight\", \"module.model.decoder.layers.13.fc2.weight\", \"module.model.decoder.layers.14.self_attn.k_proj.weight\", \"module.model.decoder.layers.14.self_attn.v_proj.weight\", \"module.model.decoder.layers.14.self_attn.q_proj.weight\", \"module.model.decoder.layers.14.self_attn.out_proj.weight\", \"module.model.decoder.layers.14.fc1.weight\", \"module.model.decoder.layers.14.fc2.weight\", \"module.model.decoder.layers.15.self_attn.k_proj.weight\", \"module.model.decoder.layers.15.self_attn.v_proj.weight\", \"module.model.decoder.layers.15.self_attn.q_proj.weight\", \"module.model.decoder.layers.15.self_attn.out_proj.weight\", \"module.model.decoder.layers.15.fc1.weight\", \"module.model.decoder.layers.15.fc2.weight\", \"module.model.decoder.layers.16.self_attn.k_proj.weight\", \"module.model.decoder.layers.16.self_attn.v_proj.weight\", \"module.model.decoder.layers.16.self_attn.q_proj.weight\", \"module.model.decoder.layers.16.self_attn.out_proj.weight\", \"module.model.decoder.layers.16.fc1.weight\", \"module.model.decoder.layers.16.fc2.weight\", \"module.model.decoder.layers.17.self_attn.k_proj.weight\", \"module.model.decoder.layers.17.self_attn.v_proj.weight\", \"module.model.decoder.layers.17.self_attn.q_proj.weight\", \"module.model.decoder.layers.17.self_attn.out_proj.weight\", \"module.model.decoder.layers.17.fc1.weight\", \"module.model.decoder.layers.17.fc2.weight\", \"module.model.decoder.layers.18.self_attn.k_proj.weight\", \"module.model.decoder.layers.18.self_attn.v_proj.weight\", \"module.model.decoder.layers.18.self_attn.q_proj.weight\", \"module.model.decoder.layers.18.self_attn.out_proj.weight\", \"module.model.decoder.layers.18.fc1.weight\", \"module.model.decoder.layers.18.fc2.weight\", \"module.model.decoder.layers.19.self_attn.k_proj.weight\", \"module.model.decoder.layers.19.self_attn.v_proj.weight\", \"module.model.decoder.layers.19.self_attn.q_proj.weight\", \"module.model.decoder.layers.19.self_attn.out_proj.weight\", \"module.model.decoder.layers.19.fc1.weight\", \"module.model.decoder.layers.19.fc2.weight\", \"module.model.decoder.layers.20.self_attn.k_proj.weight\", \"module.model.decoder.layers.20.self_attn.v_proj.weight\", \"module.model.decoder.layers.20.self_attn.q_proj.weight\", \"module.model.decoder.layers.20.self_attn.out_proj.weight\", \"module.model.decoder.layers.20.fc1.weight\", \"module.model.decoder.layers.20.fc2.weight\", \"module.model.decoder.layers.21.self_attn.k_proj.weight\", \"module.model.decoder.layers.21.self_attn.v_proj.weight\", \"module.model.decoder.layers.21.self_attn.q_proj.weight\", \"module.model.decoder.layers.21.self_attn.out_proj.weight\", \"module.model.decoder.layers.21.fc1.weight\", \"module.model.decoder.layers.21.fc2.weight\", \"module.model.decoder.layers.22.self_attn.k_proj.weight\", \"module.model.decoder.layers.22.self_attn.v_proj.weight\", \"module.model.decoder.layers.22.self_attn.q_proj.weight\", \"module.model.decoder.layers.22.self_attn.out_proj.weight\", \"module.model.decoder.layers.22.fc1.weight\", \"module.model.decoder.layers.22.fc2.weight\", \"module.model.decoder.layers.23.self_attn.k_proj.weight\", \"module.model.decoder.layers.23.self_attn.v_proj.weight\", \"module.model.decoder.layers.23.self_attn.q_proj.weight\", \"module.model.decoder.layers.23.self_attn.out_proj.weight\", \"module.model.decoder.layers.23.fc1.weight\", \"module.model.decoder.layers.23.fc2.weight\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m loaded_model \u001b[38;5;241m=\u001b[39m OPTForCausalLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfacebook/opt-350m\u001b[39m\u001b[38;5;124m'\u001b[39m, output_attentions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, output_hidden_states\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39mdevice) \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m      3\u001b[0m loaded_model \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mDataParallel(loaded_model, device_ids\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m])\n\u001b[0;32m----> 4\u001b[0m \u001b[43mload_into_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloaded_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpruned_models/opt-350m-test-0.5.pt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m loaded_model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m      7\u001b[0m _ \u001b[38;5;241m=\u001b[39m loaded_model(torch\u001b[38;5;241m.\u001b[39mrandint(high\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m10\u001b[39m)))\n",
      "File \u001b[0;32m/gs/gsfs0/home/asyed/pw/jobs/ICLR/save_pruned_model.py:55\u001b[0m, in \u001b[0;36mload_into_model\u001b[0;34m(existing_model, state_dict_path)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_into_model\u001b[39m(existing_model, state_dict_path):\n\u001b[1;32m     53\u001b[0m     apply_identity_prune(model\u001b[38;5;241m=\u001b[39mexisting_model)\n\u001b[0;32m---> 55\u001b[0m     \u001b[43mexisting_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate_dict_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1671\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1666\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   1667\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1668\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(k) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   1670\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1671\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1672\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   1673\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for DataParallel:\n\tMissing key(s) in state_dict: \"module.model.decoder.project_out.weight_orig\", \"module.model.decoder.project_out.weight_mask\", \"module.model.decoder.project_in.weight_orig\", \"module.model.decoder.project_in.weight_mask\", \"module.model.decoder.layers.0.self_attn.k_proj.weight_orig\", \"module.model.decoder.layers.0.self_attn.k_proj.weight_mask\", \"module.model.decoder.layers.0.self_attn.v_proj.weight_orig\", \"module.model.decoder.layers.0.self_attn.v_proj.weight_mask\", \"module.model.decoder.layers.0.self_attn.q_proj.weight_orig\", \"module.model.decoder.layers.0.self_attn.q_proj.weight_mask\", \"module.model.decoder.layers.0.self_attn.out_proj.weight_orig\", \"module.model.decoder.layers.0.self_attn.out_proj.weight_mask\", \"module.model.decoder.layers.0.fc1.weight_orig\", \"module.model.decoder.layers.0.fc1.weight_mask\", \"module.model.decoder.layers.0.fc2.weight_orig\", \"module.model.decoder.layers.0.fc2.weight_mask\", \"module.model.decoder.layers.1.self_attn.k_proj.weight_orig\", \"module.model.decoder.layers.1.self_attn.k_proj.weight_mask\", \"module.model.decoder.layers.1.self_attn.v_proj.weight_orig\", \"module.model.decoder.layers.1.self_attn.v_proj.weight_mask\", \"module.model.decoder.layers.1.self_attn.q_proj.weight_orig\", \"module.model.decoder.layers.1.self_attn.q_proj.weight_mask\", \"module.model.decoder.layers.1.self_attn.out_proj.weight_orig\", \"module.model.decoder.layers.1.self_attn.out_proj.weight_mask\", \"module.model.decoder.layers.1.fc1.weight_orig\", \"module.model.decoder.layers.1.fc1.weight_mask\", \"module.model.decoder.layers.1.fc2.weight_orig\", \"module.model.decoder.layers.1.fc2.weight_mask\", \"module.model.decoder.layers.2.self_attn.k_proj.weight_orig\", \"module.model.decoder.layers.2.self_attn.k_proj.weight_mask\", \"module.model.decoder.layers.2.self_attn.v_proj.weight_orig\", \"module.model.decoder.layers.2.self_attn.v_proj.weight_mask\", \"module.model.decoder.layers.2.self_attn.q_proj.weight_orig\", \"module.model.decoder.layers.2.self_attn.q_proj.weight_mask\", \"module.model.decoder.layers.2.self_attn.out_proj.weight_orig\", \"module.model.decoder.layers.2.self_attn.out_proj.weight_mask\", \"module.model.decoder.layers.2.fc1.weight_orig\", \"module.model.decoder.layers.2.fc1.weight_mask\", \"module.model.decoder.layers.2.fc2.weight_orig\", \"module.model.decoder.layers.2.fc2.weight_mask\", \"module.model.decoder.layers.3.self_attn.k_proj.weight_orig\", \"module.model.decoder.layers.3.self_attn.k_proj.weight_mask\", \"module.model.decoder.layers.3.self_attn.v_proj.weight_orig\", \"module.model.decoder.layers.3.self_attn.v_proj.weight_mask\", \"module.model.decoder.layers.3.self_attn.q_proj.weight_orig\", \"module.model.decoder.layers.3.self_attn.q_proj.weight_mask\", \"module.model.decoder.layers.3.self_attn.out_proj.weight_orig\", \"module.model.decoder.layers.3.self_attn.out_proj.weight_mask\", \"module.model.decoder.layers.3.fc1.weight_orig\", \"module.model.decoder.layers.3.fc1.weight_mask\", \"module.model.decoder.layers.3.fc2.weight_orig\", \"module.model.decoder.layers.3.fc2.weight_mask\", \"module.model.decoder.layers.4.self_attn.k_proj.weight_orig\", \"module.model.decoder.layers.4.self_attn.k_proj.weight_mask\", \"module.model.decoder.layers.4.self_attn.v_proj.weight_orig\", \"module.model.decoder.layers.4.self_attn.v_proj.weight_mask\", \"module.model.decoder.layers.4.self_attn.q_proj.weight_orig\", \"module.model.decoder.layers.4.self_attn.q_proj.weight_mask\", \"module.model.decoder.layers.4.self_attn.out_proj.weight_orig\", \"module.model.decoder.layers.4.self_attn.out_proj.weight_mask\", \"module.model.decoder.layers.4.fc1.weight_orig\", \"module.model.decoder.layers.4.fc1.weight_mask\", \"module.model.decoder.layers.4.fc2.weight_orig\", \"module.model.decoder.layers.4.fc2.weight_mask\", \"module.model.decoder.layers.5.self_attn.k_proj.weight_orig\", \"module.model.decoder.layers.5.self_attn.k_proj.weight_mask\", \"module.model.decoder.layers.5.self_attn.v_proj.weight_orig\", \"module.model.decoder.layers.5.self_attn.v_proj.weight_mask\", \"module.model.decoder.layers.5.self_attn.q_proj.weight_orig\", \"module.model.decoder.layers.5.self_attn.q_proj.weight_mask\", \"module.model.decoder.layers.5.self_attn.out_proj.weight_orig\", \"module.model.decoder.layers.5.self_attn.out_proj.weight_mask\", \"module.model.decoder.layers.5.fc1.weight_orig\", \"module.model.decoder.layers.5.fc1.weight_mask\", \"module.model.decoder.layers.5.fc2.weight_orig\", \"module.model.decoder.layers.5.fc2.weight_mask\", \"module.model.decoder.layers.6.self_attn.k_proj.weight_orig\", \"module.model.decoder.layers.6.self_attn.k_proj.weight_mask\", \"module.model.decoder.layers.6.self_attn.v_proj.weight_orig\", \"module.model.decoder.layers.6.self_attn.v_proj.weight_mask\", \"module.model.decoder.layers.6.self_attn.q_proj.weight_orig\", \"module.model.decoder.layers.6.self_attn.q_proj.weight_mask\", \"module.model.decoder.layers.6.self_attn.out_proj.weight_orig\", \"module.model.decoder.layers.6.self_attn.out_proj.weight_mask\", \"module.model.decoder.layers.6.fc1.weight_orig\", \"module.model.decoder.layers.6.fc1.weight_mask\", \"module.model.decoder.layers.6.fc2.weight_orig\", \"module.model.decoder.layers.6.fc2.weight_mask\", \"module.model.decoder.layers.7.self_attn.k_proj.weight_orig\", \"module.model.decoder.layers.7.self_attn.k_proj.weight_mask\", \"module.model.decoder.layers.7.self_attn.v_proj.weight_orig\", \"module.model.decoder.layers.7.self_attn.v_proj.weight_mask\", \"module.model.decoder.layers.7.self_attn.q_proj.weight_orig\", \"module.model.decoder.layers.7.self_attn.q_proj.weight_mask\", \"module.model.decoder.layers.7.self_attn.out_proj.weight_orig\", \"module.model.decoder.layers.7.self_attn.out_proj.weight_mask\", \"module.model.decoder.layers.7.fc1.weight_orig\", \"module.model.decoder.layers.7.fc1.weight_mask\", \"module.model.decoder.layers.7.fc2.weight_orig\", \"module.model.decoder.layers.7.fc2.weight_mask\", \"module.model.decoder.layers.8.self_attn.k_proj.weight_orig\", \"module.model.decoder.layers.8.self_attn.k_proj.weight_mask\", \"module.model.decoder.layers.8.self_attn.v_proj.weight_orig\", \"module.model.decoder.layers.8.self_attn.v_proj.weight_mask\", \"module.model.decoder.layers.8.self_attn.q_proj.weight_orig\", \"module.model.decoder.layers.8.self_attn.q_proj.weight_mask\", \"module.model.decoder.layers.8.self_attn.out_proj.weight_orig\", \"module.model.decoder.layers.8.self_attn.out_proj.weight_mask\", \"module.model.decoder.layers.8.fc1.weight_orig\", \"module.model.decoder.layers.8.fc1.weight_mask\", \"module.model.decoder.layers.8.fc2.weight_orig\", \"module.model.decoder.layers.8.fc2.weight_mask\", \"module.model.decoder.layers.9.self_attn.k_proj.weight_orig\", \"module.model.decoder.layers.9.self_attn.k_proj.weight_mask\", \"module.model.decoder.layers.9.self_attn.v_proj.weight_orig\", \"module.model.decoder.layers.9.self_attn.v_proj.weight_mask\", \"module.model.decoder.layers.9.self_attn.q_proj.weight_orig\", \"module.model.decoder.layers.9.self_attn.q_proj.weight_mask\", \"module.model.decoder.layers.9.self_attn.out_proj.weight_orig\", \"module.model.decoder.layers.9.self_attn.out_proj.weight_mask\", \"module.model.decoder.layers.9.fc1.weight_orig\", \"module.model.decoder.layers.9.fc1.weight_mask\", \"module.model.decoder.layers.9.fc2.weight_orig\", \"module.model.decoder.layers.9.fc2.weight_mask\", \"module.model.decoder.layers.10.self_attn.k_proj.weight_orig\", \"module.model.decoder.layers.10.self_attn.k_proj.weight_mask\", \"module.model.decoder.layers.10.self_attn.v_proj.weight_orig\", \"module.model.decoder.layers.10.self_attn.v_proj.weight_mask\", \"module.model.decoder.layers.10.self_attn.q_proj.weight_orig\", \"module.model.decoder.layers.10.self_attn.q_proj.weight_mask\", \"module.model.decoder.layers.10.self_attn.out_proj.weight_orig\", \"module.model.decoder.layers.10.self_attn.out_proj.weight_mask\", \"module.model.decoder.layers.10.fc1.weight_orig\", \"module.model.decoder.layers.10.fc1.weight_mask\", \"module.model.decoder.layers.10.fc2.weight_orig\", \"module.model.decoder.layers.10.fc2.weight_mask\", \"module.model.decoder.layers.11.self_attn.k_proj.weight_orig\", \"module.model.decoder.layers.11.self_attn.k_proj.weight_mask\", \"module.model.decoder.layers.11.self_attn.v_proj.weight_orig\", \"module.model.decoder.layers.11.self_attn.v_proj.weight_mask\", \"module.model.decoder.layers.11.self_attn.q_proj.weight_orig\", \"module.model.decoder.layers.11.self_attn.q_proj.weight_mask\", \"module.model.decoder.layers.11.self_attn.out_proj.weight_orig\", \"module.model.decoder.layers.11.self_attn.out_proj.weight_mask\", \"module.model.decoder.layers.11.fc1.weight_orig\", \"module.model.decoder.layers.11.fc1.weight_mask\", \"module.model.decoder.layers.11.fc2.weight_orig\", \"module.model.decoder.layers.11.fc2.weight_mask\", \"module.model.decoder.layers.12.self_attn.k_proj.weight_orig\", \"module.model.decoder.layers.12.self_attn.k_proj.weight_mask\", \"module.model.decoder.layers.12.self_attn.v_proj.weight_orig\", \"module.model.decoder.layers.12.self_attn.v_proj.weight_mask\", \"module.model.decoder.layers.12.self_attn.q_proj.weight_orig\", \"module.model.decoder.layers.12.self_attn.q_proj.weight_mask\", \"module.model.decoder.layers.12.self_attn.out_proj.weight_orig\", \"module.model.decoder.layers.12.self_attn.out_proj.weight_mask\", \"module.model.decoder.layers.12.fc1.weight_orig\", \"module.model.decoder.layers.12.fc1.weight_mask\", \"module.model.decoder.layers.12.fc2.weight_orig\", \"module.model.decoder.layers.12.fc2.weight_mask\", \"module.model.decoder.layers.13.self_attn.k_proj.weight_orig\", \"module.model.decoder.layers.13.self_attn.k_proj.weight_mask\", \"module.model.decoder.layers.13.self_attn.v_proj.weight_orig\", \"module.model.decoder.layers.13.self_attn.v_proj.weight_mask\", \"module.model.decoder.layers.13.self_attn.q_proj.weight_orig\", \"module.model.decoder.layers.13.self_attn.q_proj.weight_mask\", \"module.model.decoder.layers.13.self_attn.out_proj.weight_orig\", \"module.model.decoder.layers.13.self_attn.out_proj.weight_mask\", \"module.model.decoder.layers.13.fc1.weight_orig\", \"module.model.decoder.layers.13.fc1.weight_mask\", \"module.model.decoder.layers.13.fc2.weight_orig\", \"module.model.decoder.layers.13.fc2.weight_mask\", \"module.model.decoder.layers.14.self_attn.k_proj.weight_orig\", \"module.model.decoder.layers.14.self_attn.k_proj.weight_mask\", \"module.model.decoder.layers.14.self_attn.v_proj.weight_orig\", \"module.model.decoder.layers.14.self_attn.v_proj.weight_mask\", \"module.model.decoder.layers.14.self_attn.q_proj.weight_orig\", \"module.model.decoder.layers.14.self_attn.q_proj.weight_mask\", \"module.model.decoder.layers.14.self_attn.out_proj.weight_orig\", \"module.model.decoder.layers.14.self_attn.out_proj.weight_mask\", \"module.model.decoder.layers.14.fc1.weight_orig\", \"module.model.decoder.layers.14.fc1.weight_mask\", \"module.model.decoder.layers.14.fc2.weight_orig\", \"module.model.decoder.layers.14.fc2.weight_mask\", \"module.model.decoder.layers.15.self_attn.k_proj.weight_orig\", \"module.model.decoder.layers.15.self_attn.k_proj.weight_mask\", \"module.model.decoder.layers.15.self_attn.v_proj.weight_orig\", \"module.model.decoder.layers.15.self_attn.v_proj.weight_mask\", \"module.model.decoder.layers.15.self_attn.q_proj.weight_orig\", \"module.model.decoder.layers.15.self_attn.q_proj.weight_mask\", \"module.model.decoder.layers.15.self_attn.out_proj.weight_orig\", \"module.model.decoder.layers.15.self_attn.out_proj.weight_mask\", \"module.model.decoder.layers.15.fc1.weight_orig\", \"module.model.decoder.layers.15.fc1.weight_mask\", \"module.model.decoder.layers.15.fc2.weight_orig\", \"module.model.decoder.layers.15.fc2.weight_mask\", \"module.model.decoder.layers.16.self_attn.k_proj.weight_orig\", \"module.model.decoder.layers.16.self_attn.k_proj.weight_mask\", \"module.model.decoder.layers.16.self_attn.v_proj.weight_orig\", \"module.model.decoder.layers.16.self_attn.v_proj.weight_mask\", \"module.model.decoder.layers.16.self_attn.q_proj.weight_orig\", \"module.model.decoder.layers.16.self_attn.q_proj.weight_mask\", \"module.model.decoder.layers.16.self_attn.out_proj.weight_orig\", \"module.model.decoder.layers.16.self_attn.out_proj.weight_mask\", \"module.model.decoder.layers.16.fc1.weight_orig\", \"module.model.decoder.layers.16.fc1.weight_mask\", \"module.model.decoder.layers.16.fc2.weight_orig\", \"module.model.decoder.layers.16.fc2.weight_mask\", \"module.model.decoder.layers.17.self_attn.k_proj.weight_orig\", \"module.model.decoder.layers.17.self_attn.k_proj.weight_mask\", \"module.model.decoder.layers.17.self_attn.v_proj.weight_orig\", \"module.model.decoder.layers.17.self_attn.v_proj.weight_mask\", \"module.model.decoder.layers.17.self_attn.q_proj.weight_orig\", \"module.model.decoder.layers.17.self_attn.q_proj.weight_mask\", \"module.model.decoder.layers.17.self_attn.out_proj.weight_orig\", \"module.model.decoder.layers.17.self_attn.out_proj.weight_mask\", \"module.model.decoder.layers.17.fc1.weight_orig\", \"module.model.decoder.layers.17.fc1.weight_mask\", \"module.model.decoder.layers.17.fc2.weight_orig\", \"module.model.decoder.layers.17.fc2.weight_mask\", \"module.model.decoder.layers.18.self_attn.k_proj.weight_orig\", \"module.model.decoder.layers.18.self_attn.k_proj.weight_mask\", \"module.model.decoder.layers.18.self_attn.v_proj.weight_orig\", \"module.model.decoder.layers.18.self_attn.v_proj.weight_mask\", \"module.model.decoder.layers.18.self_attn.q_proj.weight_orig\", \"module.model.decoder.layers.18.self_attn.q_proj.weight_mask\", \"module.model.decoder.layers.18.self_attn.out_proj.weight_orig\", \"module.model.decoder.layers.18.self_attn.out_proj.weight_mask\", \"module.model.decoder.layers.18.fc1.weight_orig\", \"module.model.decoder.layers.18.fc1.weight_mask\", \"module.model.decoder.layers.18.fc2.weight_orig\", \"module.model.decoder.layers.18.fc2.weight_mask\", \"module.model.decoder.layers.19.self_attn.k_proj.weight_orig\", \"module.model.decoder.layers.19.self_attn.k_proj.weight_mask\", \"module.model.decoder.layers.19.self_attn.v_proj.weight_orig\", \"module.model.decoder.layers.19.self_attn.v_proj.weight_mask\", \"module.model.decoder.layers.19.self_attn.q_proj.weight_orig\", \"module.model.decoder.layers.19.self_attn.q_proj.weight_mask\", \"module.model.decoder.layers.19.self_attn.out_proj.weight_orig\", \"module.model.decoder.layers.19.self_attn.out_proj.weight_mask\", \"module.model.decoder.layers.19.fc1.weight_orig\", \"module.model.decoder.layers.19.fc1.weight_mask\", \"module.model.decoder.layers.19.fc2.weight_orig\", \"module.model.decoder.layers.19.fc2.weight_mask\", \"module.model.decoder.layers.20.self_attn.k_proj.weight_orig\", \"module.model.decoder.layers.20.self_attn.k_proj.weight_mask\", \"module.model.decoder.layers.20.self_attn.v_proj.weight_orig\", \"module.model.decoder.layers.20.self_attn.v_proj.weight_mask\", \"module.model.decoder.layers.20.self_attn.q_proj.weight_orig\", \"module.model.decoder.layers.20.self_attn.q_proj.weight_mask\", \"module.model.decoder.layers.20.self_attn.out_proj.weight_orig\", \"module.model.decoder.layers.20.self_attn.out_proj.weight_mask\", \"module.model.decoder.layers.20.fc1.weight_orig\", \"module.model.decoder.layers.20.fc1.weight_mask\", \"module.model.decoder.layers.20.fc2.weight_orig\", \"module.model.decoder.layers.20.fc2.weight_mask\", \"module.model.decoder.layers.21.self_attn.k_proj.weight_orig\", \"module.model.decoder.layers.21.self_attn.k_proj.weight_mask\", \"module.model.decoder.layers.21.self_attn.v_proj.weight_orig\", \"module.model.decoder.layers.21.self_attn.v_proj.weight_mask\", \"module.model.decoder.layers.21.self_attn.q_proj.weight_orig\", \"module.model.decoder.layers.21.self_attn.q_proj.weight_mask\", \"module.model.decoder.layers.21.self_attn.out_proj.weight_orig\", \"module.model.decoder.layers.21.self_attn.out_proj.weight_mask\", \"module.model.decoder.layers.21.fc1.weight_orig\", \"module.model.decoder.layers.21.fc1.weight_mask\", \"module.model.decoder.layers.21.fc2.weight_orig\", \"module.model.decoder.layers.21.fc2.weight_mask\", \"module.model.decoder.layers.22.self_attn.k_proj.weight_orig\", \"module.model.decoder.layers.22.self_attn.k_proj.weight_mask\", \"module.model.decoder.layers.22.self_attn.v_proj.weight_orig\", \"module.model.decoder.layers.22.self_attn.v_proj.weight_mask\", \"module.model.decoder.layers.22.self_attn.q_proj.weight_orig\", \"module.model.decoder.layers.22.self_attn.q_proj.weight_mask\", \"module.model.decoder.layers.22.self_attn.out_proj.weight_orig\", \"module.model.decoder.layers.22.self_attn.out_proj.weight_mask\", \"module.model.decoder.layers.22.fc1.weight_orig\", \"module.model.decoder.layers.22.fc1.weight_mask\", \"module.model.decoder.layers.22.fc2.weight_orig\", \"module.model.decoder.layers.22.fc2.weight_mask\", \"module.model.decoder.layers.23.self_attn.k_proj.weight_orig\", \"module.model.decoder.layers.23.self_attn.k_proj.weight_mask\", \"module.model.decoder.layers.23.self_attn.v_proj.weight_orig\", \"module.model.decoder.layers.23.self_attn.v_proj.weight_mask\", \"module.model.decoder.layers.23.self_attn.q_proj.weight_orig\", \"module.model.decoder.layers.23.self_attn.q_proj.weight_mask\", \"module.model.decoder.layers.23.self_attn.out_proj.weight_orig\", \"module.model.decoder.layers.23.self_attn.out_proj.weight_mask\", \"module.model.decoder.layers.23.fc1.weight_orig\", \"module.model.decoder.layers.23.fc1.weight_mask\", \"module.model.decoder.layers.23.fc2.weight_orig\", \"module.model.decoder.layers.23.fc2.weight_mask\". \n\tUnexpected key(s) in state_dict: \"module.model.decoder.project_out.weight\", \"module.model.decoder.project_in.weight\", \"module.model.decoder.layers.0.self_attn.k_proj.weight\", \"module.model.decoder.layers.0.self_attn.v_proj.weight\", \"module.model.decoder.layers.0.self_attn.q_proj.weight\", \"module.model.decoder.layers.0.self_attn.out_proj.weight\", \"module.model.decoder.layers.0.fc1.weight\", \"module.model.decoder.layers.0.fc2.weight\", \"module.model.decoder.layers.1.self_attn.k_proj.weight\", \"module.model.decoder.layers.1.self_attn.v_proj.weight\", \"module.model.decoder.layers.1.self_attn.q_proj.weight\", \"module.model.decoder.layers.1.self_attn.out_proj.weight\", \"module.model.decoder.layers.1.fc1.weight\", \"module.model.decoder.layers.1.fc2.weight\", \"module.model.decoder.layers.2.self_attn.k_proj.weight\", \"module.model.decoder.layers.2.self_attn.v_proj.weight\", \"module.model.decoder.layers.2.self_attn.q_proj.weight\", \"module.model.decoder.layers.2.self_attn.out_proj.weight\", \"module.model.decoder.layers.2.fc1.weight\", \"module.model.decoder.layers.2.fc2.weight\", \"module.model.decoder.layers.3.self_attn.k_proj.weight\", \"module.model.decoder.layers.3.self_attn.v_proj.weight\", \"module.model.decoder.layers.3.self_attn.q_proj.weight\", \"module.model.decoder.layers.3.self_attn.out_proj.weight\", \"module.model.decoder.layers.3.fc1.weight\", \"module.model.decoder.layers.3.fc2.weight\", \"module.model.decoder.layers.4.self_attn.k_proj.weight\", \"module.model.decoder.layers.4.self_attn.v_proj.weight\", \"module.model.decoder.layers.4.self_attn.q_proj.weight\", \"module.model.decoder.layers.4.self_attn.out_proj.weight\", \"module.model.decoder.layers.4.fc1.weight\", \"module.model.decoder.layers.4.fc2.weight\", \"module.model.decoder.layers.5.self_attn.k_proj.weight\", \"module.model.decoder.layers.5.self_attn.v_proj.weight\", \"module.model.decoder.layers.5.self_attn.q_proj.weight\", \"module.model.decoder.layers.5.self_attn.out_proj.weight\", \"module.model.decoder.layers.5.fc1.weight\", \"module.model.decoder.layers.5.fc2.weight\", \"module.model.decoder.layers.6.self_attn.k_proj.weight\", \"module.model.decoder.layers.6.self_attn.v_proj.weight\", \"module.model.decoder.layers.6.self_attn.q_proj.weight\", \"module.model.decoder.layers.6.self_attn.out_proj.weight\", \"module.model.decoder.layers.6.fc1.weight\", \"module.model.decoder.layers.6.fc2.weight\", \"module.model.decoder.layers.7.self_attn.k_proj.weight\", \"module.model.decoder.layers.7.self_attn.v_proj.weight\", \"module.model.decoder.layers.7.self_attn.q_proj.weight\", \"module.model.decoder.layers.7.self_attn.out_proj.weight\", \"module.model.decoder.layers.7.fc1.weight\", \"module.model.decoder.layers.7.fc2.weight\", \"module.model.decoder.layers.8.self_attn.k_proj.weight\", \"module.model.decoder.layers.8.self_attn.v_proj.weight\", \"module.model.decoder.layers.8.self_attn.q_proj.weight\", \"module.model.decoder.layers.8.self_attn.out_proj.weight\", \"module.model.decoder.layers.8.fc1.weight\", \"module.model.decoder.layers.8.fc2.weight\", \"module.model.decoder.layers.9.self_attn.k_proj.weight\", \"module.model.decoder.layers.9.self_attn.v_proj.weight\", \"module.model.decoder.layers.9.self_attn.q_proj.weight\", \"module.model.decoder.layers.9.self_attn.out_proj.weight\", \"module.model.decoder.layers.9.fc1.weight\", \"module.model.decoder.layers.9.fc2.weight\", \"module.model.decoder.layers.10.self_attn.k_proj.weight\", \"module.model.decoder.layers.10.self_attn.v_proj.weight\", \"module.model.decoder.layers.10.self_attn.q_proj.weight\", \"module.model.decoder.layers.10.self_attn.out_proj.weight\", \"module.model.decoder.layers.10.fc1.weight\", \"module.model.decoder.layers.10.fc2.weight\", \"module.model.decoder.layers.11.self_attn.k_proj.weight\", \"module.model.decoder.layers.11.self_attn.v_proj.weight\", \"module.model.decoder.layers.11.self_attn.q_proj.weight\", \"module.model.decoder.layers.11.self_attn.out_proj.weight\", \"module.model.decoder.layers.11.fc1.weight\", \"module.model.decoder.layers.11.fc2.weight\", \"module.model.decoder.layers.12.self_attn.k_proj.weight\", \"module.model.decoder.layers.12.self_attn.v_proj.weight\", \"module.model.decoder.layers.12.self_attn.q_proj.weight\", \"module.model.decoder.layers.12.self_attn.out_proj.weight\", \"module.model.decoder.layers.12.fc1.weight\", \"module.model.decoder.layers.12.fc2.weight\", \"module.model.decoder.layers.13.self_attn.k_proj.weight\", \"module.model.decoder.layers.13.self_attn.v_proj.weight\", \"module.model.decoder.layers.13.self_attn.q_proj.weight\", \"module.model.decoder.layers.13.self_attn.out_proj.weight\", \"module.model.decoder.layers.13.fc1.weight\", \"module.model.decoder.layers.13.fc2.weight\", \"module.model.decoder.layers.14.self_attn.k_proj.weight\", \"module.model.decoder.layers.14.self_attn.v_proj.weight\", \"module.model.decoder.layers.14.self_attn.q_proj.weight\", \"module.model.decoder.layers.14.self_attn.out_proj.weight\", \"module.model.decoder.layers.14.fc1.weight\", \"module.model.decoder.layers.14.fc2.weight\", \"module.model.decoder.layers.15.self_attn.k_proj.weight\", \"module.model.decoder.layers.15.self_attn.v_proj.weight\", \"module.model.decoder.layers.15.self_attn.q_proj.weight\", \"module.model.decoder.layers.15.self_attn.out_proj.weight\", \"module.model.decoder.layers.15.fc1.weight\", \"module.model.decoder.layers.15.fc2.weight\", \"module.model.decoder.layers.16.self_attn.k_proj.weight\", \"module.model.decoder.layers.16.self_attn.v_proj.weight\", \"module.model.decoder.layers.16.self_attn.q_proj.weight\", \"module.model.decoder.layers.16.self_attn.out_proj.weight\", \"module.model.decoder.layers.16.fc1.weight\", \"module.model.decoder.layers.16.fc2.weight\", \"module.model.decoder.layers.17.self_attn.k_proj.weight\", \"module.model.decoder.layers.17.self_attn.v_proj.weight\", \"module.model.decoder.layers.17.self_attn.q_proj.weight\", \"module.model.decoder.layers.17.self_attn.out_proj.weight\", \"module.model.decoder.layers.17.fc1.weight\", \"module.model.decoder.layers.17.fc2.weight\", \"module.model.decoder.layers.18.self_attn.k_proj.weight\", \"module.model.decoder.layers.18.self_attn.v_proj.weight\", \"module.model.decoder.layers.18.self_attn.q_proj.weight\", \"module.model.decoder.layers.18.self_attn.out_proj.weight\", \"module.model.decoder.layers.18.fc1.weight\", \"module.model.decoder.layers.18.fc2.weight\", \"module.model.decoder.layers.19.self_attn.k_proj.weight\", \"module.model.decoder.layers.19.self_attn.v_proj.weight\", \"module.model.decoder.layers.19.self_attn.q_proj.weight\", \"module.model.decoder.layers.19.self_attn.out_proj.weight\", \"module.model.decoder.layers.19.fc1.weight\", \"module.model.decoder.layers.19.fc2.weight\", \"module.model.decoder.layers.20.self_attn.k_proj.weight\", \"module.model.decoder.layers.20.self_attn.v_proj.weight\", \"module.model.decoder.layers.20.self_attn.q_proj.weight\", \"module.model.decoder.layers.20.self_attn.out_proj.weight\", \"module.model.decoder.layers.20.fc1.weight\", \"module.model.decoder.layers.20.fc2.weight\", \"module.model.decoder.layers.21.self_attn.k_proj.weight\", \"module.model.decoder.layers.21.self_attn.v_proj.weight\", \"module.model.decoder.layers.21.self_attn.q_proj.weight\", \"module.model.decoder.layers.21.self_attn.out_proj.weight\", \"module.model.decoder.layers.21.fc1.weight\", \"module.model.decoder.layers.21.fc2.weight\", \"module.model.decoder.layers.22.self_attn.k_proj.weight\", \"module.model.decoder.layers.22.self_attn.v_proj.weight\", \"module.model.decoder.layers.22.self_attn.q_proj.weight\", \"module.model.decoder.layers.22.self_attn.out_proj.weight\", \"module.model.decoder.layers.22.fc1.weight\", \"module.model.decoder.layers.22.fc2.weight\", \"module.model.decoder.layers.23.self_attn.k_proj.weight\", \"module.model.decoder.layers.23.self_attn.v_proj.weight\", \"module.model.decoder.layers.23.self_attn.q_proj.weight\", \"module.model.decoder.layers.23.self_attn.out_proj.weight\", \"module.model.decoder.layers.23.fc1.weight\", \"module.model.decoder.layers.23.fc2.weight\". "
     ]
    }
   ],
   "source": [
    "from save_pruned_model import load_into_model\n",
    "loaded_model = OPTForCausalLM.from_pretrained(f'facebook/opt-350m', output_attentions=True, output_hidden_states=True).to(device=device) # type: ignore\n",
    "loaded_model = torch.nn.DataParallel(loaded_model, device_ids=[0,1,2,3])\n",
    "load_into_model(loaded_model, f'pruned_models/opt-350m-test-0.5.pt')\n",
    "\n",
    "loaded_model.eval()\n",
    "_ = loaded_model(torch.randint(high=20, size=(1,10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0., device='cuda:0')\n",
      "tensor(0.5005, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "def get_prop_zeros(model):\n",
    "    return torch.sum(model.module.get_decoder().layers[0].self_attn.k_proj.weight == 0) / (torch.sum(model.module.get_decoder().layers[0].self_attn.k_proj.weight == 0) + torch.sum(model.module.get_decoder().layers[0].self_attn.k_proj.weight != 0))\n",
    "\n",
    "print(get_prop_zeros(loaded_model))\n",
    "print(get_prop_zeros(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prune_list = []\n",
    "layer_blacklist = ['', 'module','module.model','module.model.decoder',\n",
    "                   'module.model.decoder.embed_tokens',\n",
    "                   'module.model.decoder.embed_tokens',\n",
    "                   'module.model.decoder.embed_positions']\n",
    "for name, module in model.named_modules():\n",
    "    # skip the embed layer or skip norms which have 1 dimension\n",
    "    if name in layer_blacklist or 'norm' in name or not isinstance(module, torch.nn.Module):\n",
    "        continue\n",
    "    prune_list.append((module, 'weight'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prune to 0s\n",
    "class ThresholdPruning(prune.BasePruningMethod):\n",
    "    PRUNING_TYPE = \"unstructured\"\n",
    "\n",
    "    # default threshold is 0, prunes weights that are already 0 (for training)\n",
    "    def __init__(self, threshold=1e-8):\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def compute_mask(self, tensor, default_mask):\n",
    "        return torch.abs(tensor) >= self.threshold\n",
    "    \n",
    "prune.global_unstructured(prune_list,\n",
    "                          pruning_method=ThresholdPruning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "01ca8e50707366aa71ffa41d1a1f13415d8b38eae741916c87480058f12910d2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
