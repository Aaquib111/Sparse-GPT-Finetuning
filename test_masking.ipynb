{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# %%capture\n",
    "from transformers import AutoTokenizer, AutoModel, pipeline, OPTForCausalLM\n",
    "\n",
    "model_name=\"facebook/opt-350m\"\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False)\n",
    "\n",
    "# Load model with pre-trained head\n",
    "model = OPTForCausalLM.from_pretrained(model_name, output_attentions=True, output_hidden_states=True)\n",
    "\n",
    "generator = pipeline('text-generation', model=model_name)\n",
    "#generator = pipeline('text-generation', model=model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.decoder.embed_tokens.weight\n",
      "model.decoder.embed_positions.weight\n",
      "model.decoder.project_out.weight\n",
      "model.decoder.project_in.weight\n",
      "model.decoder.layers.0.self_attn.k_proj.weight\n",
      "model.decoder.layers.0.self_attn.k_proj.bias\n",
      "model.decoder.layers.0.self_attn.v_proj.weight\n",
      "model.decoder.layers.0.self_attn.v_proj.bias\n",
      "model.decoder.layers.0.self_attn.q_proj.weight\n",
      "model.decoder.layers.0.self_attn.q_proj.bias\n",
      "model.decoder.layers.0.self_attn.out_proj.weight\n",
      "model.decoder.layers.0.self_attn.out_proj.bias\n",
      "model.decoder.layers.0.self_attn_layer_norm.weight\n",
      "model.decoder.layers.0.self_attn_layer_norm.bias\n",
      "model.decoder.layers.0.fc1.weight\n",
      "model.decoder.layers.0.fc1.bias\n",
      "model.decoder.layers.0.fc2.weight\n",
      "model.decoder.layers.0.fc2.bias\n",
      "model.decoder.layers.0.final_layer_norm.weight\n",
      "model.decoder.layers.0.final_layer_norm.bias\n",
      "model.decoder.layers.1.self_attn.k_proj.weight\n",
      "model.decoder.layers.1.self_attn.k_proj.bias\n",
      "model.decoder.layers.1.self_attn.v_proj.weight\n",
      "model.decoder.layers.1.self_attn.v_proj.bias\n",
      "model.decoder.layers.1.self_attn.q_proj.weight\n",
      "model.decoder.layers.1.self_attn.q_proj.bias\n",
      "model.decoder.layers.1.self_attn.out_proj.weight\n",
      "model.decoder.layers.1.self_attn.out_proj.bias\n",
      "model.decoder.layers.1.self_attn_layer_norm.weight\n",
      "model.decoder.layers.1.self_attn_layer_norm.bias\n",
      "model.decoder.layers.1.fc1.weight\n",
      "model.decoder.layers.1.fc1.bias\n",
      "model.decoder.layers.1.fc2.weight\n",
      "model.decoder.layers.1.fc2.bias\n",
      "model.decoder.layers.1.final_layer_norm.weight\n",
      "model.decoder.layers.1.final_layer_norm.bias\n",
      "model.decoder.layers.2.self_attn.k_proj.weight\n",
      "model.decoder.layers.2.self_attn.k_proj.bias\n",
      "model.decoder.layers.2.self_attn.v_proj.weight\n",
      "model.decoder.layers.2.self_attn.v_proj.bias\n",
      "model.decoder.layers.2.self_attn.q_proj.weight\n",
      "model.decoder.layers.2.self_attn.q_proj.bias\n",
      "model.decoder.layers.2.self_attn.out_proj.weight\n",
      "model.decoder.layers.2.self_attn.out_proj.bias\n",
      "model.decoder.layers.2.self_attn_layer_norm.weight\n",
      "model.decoder.layers.2.self_attn_layer_norm.bias\n",
      "model.decoder.layers.2.fc1.weight\n",
      "model.decoder.layers.2.fc1.bias\n",
      "model.decoder.layers.2.fc2.weight\n",
      "model.decoder.layers.2.fc2.bias\n",
      "model.decoder.layers.2.final_layer_norm.weight\n",
      "model.decoder.layers.2.final_layer_norm.bias\n",
      "model.decoder.layers.3.self_attn.k_proj.weight\n",
      "model.decoder.layers.3.self_attn.k_proj.bias\n",
      "model.decoder.layers.3.self_attn.v_proj.weight\n",
      "model.decoder.layers.3.self_attn.v_proj.bias\n",
      "model.decoder.layers.3.self_attn.q_proj.weight\n",
      "model.decoder.layers.3.self_attn.q_proj.bias\n",
      "model.decoder.layers.3.self_attn.out_proj.weight\n",
      "model.decoder.layers.3.self_attn.out_proj.bias\n",
      "model.decoder.layers.3.self_attn_layer_norm.weight\n",
      "model.decoder.layers.3.self_attn_layer_norm.bias\n",
      "model.decoder.layers.3.fc1.weight\n",
      "model.decoder.layers.3.fc1.bias\n",
      "model.decoder.layers.3.fc2.weight\n",
      "model.decoder.layers.3.fc2.bias\n",
      "model.decoder.layers.3.final_layer_norm.weight\n",
      "model.decoder.layers.3.final_layer_norm.bias\n",
      "model.decoder.layers.4.self_attn.k_proj.weight\n",
      "model.decoder.layers.4.self_attn.k_proj.bias\n",
      "model.decoder.layers.4.self_attn.v_proj.weight\n",
      "model.decoder.layers.4.self_attn.v_proj.bias\n",
      "model.decoder.layers.4.self_attn.q_proj.weight\n",
      "model.decoder.layers.4.self_attn.q_proj.bias\n",
      "model.decoder.layers.4.self_attn.out_proj.weight\n",
      "model.decoder.layers.4.self_attn.out_proj.bias\n",
      "model.decoder.layers.4.self_attn_layer_norm.weight\n",
      "model.decoder.layers.4.self_attn_layer_norm.bias\n",
      "model.decoder.layers.4.fc1.weight\n",
      "model.decoder.layers.4.fc1.bias\n",
      "model.decoder.layers.4.fc2.weight\n",
      "model.decoder.layers.4.fc2.bias\n",
      "model.decoder.layers.4.final_layer_norm.weight\n",
      "model.decoder.layers.4.final_layer_norm.bias\n",
      "model.decoder.layers.5.self_attn.k_proj.weight\n",
      "model.decoder.layers.5.self_attn.k_proj.bias\n",
      "model.decoder.layers.5.self_attn.v_proj.weight\n",
      "model.decoder.layers.5.self_attn.v_proj.bias\n",
      "model.decoder.layers.5.self_attn.q_proj.weight\n",
      "model.decoder.layers.5.self_attn.q_proj.bias\n",
      "model.decoder.layers.5.self_attn.out_proj.weight\n",
      "model.decoder.layers.5.self_attn.out_proj.bias\n",
      "model.decoder.layers.5.self_attn_layer_norm.weight\n",
      "model.decoder.layers.5.self_attn_layer_norm.bias\n",
      "model.decoder.layers.5.fc1.weight\n",
      "model.decoder.layers.5.fc1.bias\n",
      "model.decoder.layers.5.fc2.weight\n",
      "model.decoder.layers.5.fc2.bias\n",
      "model.decoder.layers.5.final_layer_norm.weight\n",
      "model.decoder.layers.5.final_layer_norm.bias\n",
      "model.decoder.layers.6.self_attn.k_proj.weight\n",
      "model.decoder.layers.6.self_attn.k_proj.bias\n",
      "model.decoder.layers.6.self_attn.v_proj.weight\n",
      "model.decoder.layers.6.self_attn.v_proj.bias\n",
      "model.decoder.layers.6.self_attn.q_proj.weight\n",
      "model.decoder.layers.6.self_attn.q_proj.bias\n",
      "model.decoder.layers.6.self_attn.out_proj.weight\n",
      "model.decoder.layers.6.self_attn.out_proj.bias\n",
      "model.decoder.layers.6.self_attn_layer_norm.weight\n",
      "model.decoder.layers.6.self_attn_layer_norm.bias\n",
      "model.decoder.layers.6.fc1.weight\n",
      "model.decoder.layers.6.fc1.bias\n",
      "model.decoder.layers.6.fc2.weight\n",
      "model.decoder.layers.6.fc2.bias\n",
      "model.decoder.layers.6.final_layer_norm.weight\n",
      "model.decoder.layers.6.final_layer_norm.bias\n",
      "model.decoder.layers.7.self_attn.k_proj.weight\n",
      "model.decoder.layers.7.self_attn.k_proj.bias\n",
      "model.decoder.layers.7.self_attn.v_proj.weight\n",
      "model.decoder.layers.7.self_attn.v_proj.bias\n",
      "model.decoder.layers.7.self_attn.q_proj.weight\n",
      "model.decoder.layers.7.self_attn.q_proj.bias\n",
      "model.decoder.layers.7.self_attn.out_proj.weight\n",
      "model.decoder.layers.7.self_attn.out_proj.bias\n",
      "model.decoder.layers.7.self_attn_layer_norm.weight\n",
      "model.decoder.layers.7.self_attn_layer_norm.bias\n",
      "model.decoder.layers.7.fc1.weight\n",
      "model.decoder.layers.7.fc1.bias\n",
      "model.decoder.layers.7.fc2.weight\n",
      "model.decoder.layers.7.fc2.bias\n",
      "model.decoder.layers.7.final_layer_norm.weight\n",
      "model.decoder.layers.7.final_layer_norm.bias\n",
      "model.decoder.layers.8.self_attn.k_proj.weight\n",
      "model.decoder.layers.8.self_attn.k_proj.bias\n",
      "model.decoder.layers.8.self_attn.v_proj.weight\n",
      "model.decoder.layers.8.self_attn.v_proj.bias\n",
      "model.decoder.layers.8.self_attn.q_proj.weight\n",
      "model.decoder.layers.8.self_attn.q_proj.bias\n",
      "model.decoder.layers.8.self_attn.out_proj.weight\n",
      "model.decoder.layers.8.self_attn.out_proj.bias\n",
      "model.decoder.layers.8.self_attn_layer_norm.weight\n",
      "model.decoder.layers.8.self_attn_layer_norm.bias\n",
      "model.decoder.layers.8.fc1.weight\n",
      "model.decoder.layers.8.fc1.bias\n",
      "model.decoder.layers.8.fc2.weight\n",
      "model.decoder.layers.8.fc2.bias\n",
      "model.decoder.layers.8.final_layer_norm.weight\n",
      "model.decoder.layers.8.final_layer_norm.bias\n",
      "model.decoder.layers.9.self_attn.k_proj.weight\n",
      "model.decoder.layers.9.self_attn.k_proj.bias\n",
      "model.decoder.layers.9.self_attn.v_proj.weight\n",
      "model.decoder.layers.9.self_attn.v_proj.bias\n",
      "model.decoder.layers.9.self_attn.q_proj.weight\n",
      "model.decoder.layers.9.self_attn.q_proj.bias\n",
      "model.decoder.layers.9.self_attn.out_proj.weight\n",
      "model.decoder.layers.9.self_attn.out_proj.bias\n",
      "model.decoder.layers.9.self_attn_layer_norm.weight\n",
      "model.decoder.layers.9.self_attn_layer_norm.bias\n",
      "model.decoder.layers.9.fc1.weight\n",
      "model.decoder.layers.9.fc1.bias\n",
      "model.decoder.layers.9.fc2.weight\n",
      "model.decoder.layers.9.fc2.bias\n",
      "model.decoder.layers.9.final_layer_norm.weight\n",
      "model.decoder.layers.9.final_layer_norm.bias\n",
      "model.decoder.layers.10.self_attn.k_proj.weight\n",
      "model.decoder.layers.10.self_attn.k_proj.bias\n",
      "model.decoder.layers.10.self_attn.v_proj.weight\n",
      "model.decoder.layers.10.self_attn.v_proj.bias\n",
      "model.decoder.layers.10.self_attn.q_proj.weight\n",
      "model.decoder.layers.10.self_attn.q_proj.bias\n",
      "model.decoder.layers.10.self_attn.out_proj.weight\n",
      "model.decoder.layers.10.self_attn.out_proj.bias\n",
      "model.decoder.layers.10.self_attn_layer_norm.weight\n",
      "model.decoder.layers.10.self_attn_layer_norm.bias\n",
      "model.decoder.layers.10.fc1.weight\n",
      "model.decoder.layers.10.fc1.bias\n",
      "model.decoder.layers.10.fc2.weight\n",
      "model.decoder.layers.10.fc2.bias\n",
      "model.decoder.layers.10.final_layer_norm.weight\n",
      "model.decoder.layers.10.final_layer_norm.bias\n",
      "model.decoder.layers.11.self_attn.k_proj.weight\n",
      "model.decoder.layers.11.self_attn.k_proj.bias\n",
      "model.decoder.layers.11.self_attn.v_proj.weight\n",
      "model.decoder.layers.11.self_attn.v_proj.bias\n",
      "model.decoder.layers.11.self_attn.q_proj.weight\n",
      "model.decoder.layers.11.self_attn.q_proj.bias\n",
      "model.decoder.layers.11.self_attn.out_proj.weight\n",
      "model.decoder.layers.11.self_attn.out_proj.bias\n",
      "model.decoder.layers.11.self_attn_layer_norm.weight\n",
      "model.decoder.layers.11.self_attn_layer_norm.bias\n",
      "model.decoder.layers.11.fc1.weight\n",
      "model.decoder.layers.11.fc1.bias\n",
      "model.decoder.layers.11.fc2.weight\n",
      "model.decoder.layers.11.fc2.bias\n",
      "model.decoder.layers.11.final_layer_norm.weight\n",
      "model.decoder.layers.11.final_layer_norm.bias\n",
      "model.decoder.layers.12.self_attn.k_proj.weight\n",
      "model.decoder.layers.12.self_attn.k_proj.bias\n",
      "model.decoder.layers.12.self_attn.v_proj.weight\n",
      "model.decoder.layers.12.self_attn.v_proj.bias\n",
      "model.decoder.layers.12.self_attn.q_proj.weight\n",
      "model.decoder.layers.12.self_attn.q_proj.bias\n",
      "model.decoder.layers.12.self_attn.out_proj.weight\n",
      "model.decoder.layers.12.self_attn.out_proj.bias\n",
      "model.decoder.layers.12.self_attn_layer_norm.weight\n",
      "model.decoder.layers.12.self_attn_layer_norm.bias\n",
      "model.decoder.layers.12.fc1.weight\n",
      "model.decoder.layers.12.fc1.bias\n",
      "model.decoder.layers.12.fc2.weight\n",
      "model.decoder.layers.12.fc2.bias\n",
      "model.decoder.layers.12.final_layer_norm.weight\n",
      "model.decoder.layers.12.final_layer_norm.bias\n",
      "model.decoder.layers.13.self_attn.k_proj.weight\n",
      "model.decoder.layers.13.self_attn.k_proj.bias\n",
      "model.decoder.layers.13.self_attn.v_proj.weight\n",
      "model.decoder.layers.13.self_attn.v_proj.bias\n",
      "model.decoder.layers.13.self_attn.q_proj.weight\n",
      "model.decoder.layers.13.self_attn.q_proj.bias\n",
      "model.decoder.layers.13.self_attn.out_proj.weight\n",
      "model.decoder.layers.13.self_attn.out_proj.bias\n",
      "model.decoder.layers.13.self_attn_layer_norm.weight\n",
      "model.decoder.layers.13.self_attn_layer_norm.bias\n",
      "model.decoder.layers.13.fc1.weight\n",
      "model.decoder.layers.13.fc1.bias\n",
      "model.decoder.layers.13.fc2.weight\n",
      "model.decoder.layers.13.fc2.bias\n",
      "model.decoder.layers.13.final_layer_norm.weight\n",
      "model.decoder.layers.13.final_layer_norm.bias\n",
      "model.decoder.layers.14.self_attn.k_proj.weight\n",
      "model.decoder.layers.14.self_attn.k_proj.bias\n",
      "model.decoder.layers.14.self_attn.v_proj.weight\n",
      "model.decoder.layers.14.self_attn.v_proj.bias\n",
      "model.decoder.layers.14.self_attn.q_proj.weight\n",
      "model.decoder.layers.14.self_attn.q_proj.bias\n",
      "model.decoder.layers.14.self_attn.out_proj.weight\n",
      "model.decoder.layers.14.self_attn.out_proj.bias\n",
      "model.decoder.layers.14.self_attn_layer_norm.weight\n",
      "model.decoder.layers.14.self_attn_layer_norm.bias\n",
      "model.decoder.layers.14.fc1.weight\n",
      "model.decoder.layers.14.fc1.bias\n",
      "model.decoder.layers.14.fc2.weight\n",
      "model.decoder.layers.14.fc2.bias\n",
      "model.decoder.layers.14.final_layer_norm.weight\n",
      "model.decoder.layers.14.final_layer_norm.bias\n",
      "model.decoder.layers.15.self_attn.k_proj.weight\n",
      "model.decoder.layers.15.self_attn.k_proj.bias\n",
      "model.decoder.layers.15.self_attn.v_proj.weight\n",
      "model.decoder.layers.15.self_attn.v_proj.bias\n",
      "model.decoder.layers.15.self_attn.q_proj.weight\n",
      "model.decoder.layers.15.self_attn.q_proj.bias\n",
      "model.decoder.layers.15.self_attn.out_proj.weight\n",
      "model.decoder.layers.15.self_attn.out_proj.bias\n",
      "model.decoder.layers.15.self_attn_layer_norm.weight\n",
      "model.decoder.layers.15.self_attn_layer_norm.bias\n",
      "model.decoder.layers.15.fc1.weight\n",
      "model.decoder.layers.15.fc1.bias\n",
      "model.decoder.layers.15.fc2.weight\n",
      "model.decoder.layers.15.fc2.bias\n",
      "model.decoder.layers.15.final_layer_norm.weight\n",
      "model.decoder.layers.15.final_layer_norm.bias\n",
      "model.decoder.layers.16.self_attn.k_proj.weight\n",
      "model.decoder.layers.16.self_attn.k_proj.bias\n",
      "model.decoder.layers.16.self_attn.v_proj.weight\n",
      "model.decoder.layers.16.self_attn.v_proj.bias\n",
      "model.decoder.layers.16.self_attn.q_proj.weight\n",
      "model.decoder.layers.16.self_attn.q_proj.bias\n",
      "model.decoder.layers.16.self_attn.out_proj.weight\n",
      "model.decoder.layers.16.self_attn.out_proj.bias\n",
      "model.decoder.layers.16.self_attn_layer_norm.weight\n",
      "model.decoder.layers.16.self_attn_layer_norm.bias\n",
      "model.decoder.layers.16.fc1.weight\n",
      "model.decoder.layers.16.fc1.bias\n",
      "model.decoder.layers.16.fc2.weight\n",
      "model.decoder.layers.16.fc2.bias\n",
      "model.decoder.layers.16.final_layer_norm.weight\n",
      "model.decoder.layers.16.final_layer_norm.bias\n",
      "model.decoder.layers.17.self_attn.k_proj.weight\n",
      "model.decoder.layers.17.self_attn.k_proj.bias\n",
      "model.decoder.layers.17.self_attn.v_proj.weight\n",
      "model.decoder.layers.17.self_attn.v_proj.bias\n",
      "model.decoder.layers.17.self_attn.q_proj.weight\n",
      "model.decoder.layers.17.self_attn.q_proj.bias\n",
      "model.decoder.layers.17.self_attn.out_proj.weight\n",
      "model.decoder.layers.17.self_attn.out_proj.bias\n",
      "model.decoder.layers.17.self_attn_layer_norm.weight\n",
      "model.decoder.layers.17.self_attn_layer_norm.bias\n",
      "model.decoder.layers.17.fc1.weight\n",
      "model.decoder.layers.17.fc1.bias\n",
      "model.decoder.layers.17.fc2.weight\n",
      "model.decoder.layers.17.fc2.bias\n",
      "model.decoder.layers.17.final_layer_norm.weight\n",
      "model.decoder.layers.17.final_layer_norm.bias\n",
      "model.decoder.layers.18.self_attn.k_proj.weight\n",
      "model.decoder.layers.18.self_attn.k_proj.bias\n",
      "model.decoder.layers.18.self_attn.v_proj.weight\n",
      "model.decoder.layers.18.self_attn.v_proj.bias\n",
      "model.decoder.layers.18.self_attn.q_proj.weight\n",
      "model.decoder.layers.18.self_attn.q_proj.bias\n",
      "model.decoder.layers.18.self_attn.out_proj.weight\n",
      "model.decoder.layers.18.self_attn.out_proj.bias\n",
      "model.decoder.layers.18.self_attn_layer_norm.weight\n",
      "model.decoder.layers.18.self_attn_layer_norm.bias\n",
      "model.decoder.layers.18.fc1.weight\n",
      "model.decoder.layers.18.fc1.bias\n",
      "model.decoder.layers.18.fc2.weight\n",
      "model.decoder.layers.18.fc2.bias\n",
      "model.decoder.layers.18.final_layer_norm.weight\n",
      "model.decoder.layers.18.final_layer_norm.bias\n",
      "model.decoder.layers.19.self_attn.k_proj.weight\n",
      "model.decoder.layers.19.self_attn.k_proj.bias\n",
      "model.decoder.layers.19.self_attn.v_proj.weight\n",
      "model.decoder.layers.19.self_attn.v_proj.bias\n",
      "model.decoder.layers.19.self_attn.q_proj.weight\n",
      "model.decoder.layers.19.self_attn.q_proj.bias\n",
      "model.decoder.layers.19.self_attn.out_proj.weight\n",
      "model.decoder.layers.19.self_attn.out_proj.bias\n",
      "model.decoder.layers.19.self_attn_layer_norm.weight\n",
      "model.decoder.layers.19.self_attn_layer_norm.bias\n",
      "model.decoder.layers.19.fc1.weight\n",
      "model.decoder.layers.19.fc1.bias\n",
      "model.decoder.layers.19.fc2.weight\n",
      "model.decoder.layers.19.fc2.bias\n",
      "model.decoder.layers.19.final_layer_norm.weight\n",
      "model.decoder.layers.19.final_layer_norm.bias\n",
      "model.decoder.layers.20.self_attn.k_proj.weight\n",
      "model.decoder.layers.20.self_attn.k_proj.bias\n",
      "model.decoder.layers.20.self_attn.v_proj.weight\n",
      "model.decoder.layers.20.self_attn.v_proj.bias\n",
      "model.decoder.layers.20.self_attn.q_proj.weight\n",
      "model.decoder.layers.20.self_attn.q_proj.bias\n",
      "model.decoder.layers.20.self_attn.out_proj.weight\n",
      "model.decoder.layers.20.self_attn.out_proj.bias\n",
      "model.decoder.layers.20.self_attn_layer_norm.weight\n",
      "model.decoder.layers.20.self_attn_layer_norm.bias\n",
      "model.decoder.layers.20.fc1.weight\n",
      "model.decoder.layers.20.fc1.bias\n",
      "model.decoder.layers.20.fc2.weight\n",
      "model.decoder.layers.20.fc2.bias\n",
      "model.decoder.layers.20.final_layer_norm.weight\n",
      "model.decoder.layers.20.final_layer_norm.bias\n",
      "model.decoder.layers.21.self_attn.k_proj.weight\n",
      "model.decoder.layers.21.self_attn.k_proj.bias\n",
      "model.decoder.layers.21.self_attn.v_proj.weight\n",
      "model.decoder.layers.21.self_attn.v_proj.bias\n",
      "model.decoder.layers.21.self_attn.q_proj.weight\n",
      "model.decoder.layers.21.self_attn.q_proj.bias\n",
      "model.decoder.layers.21.self_attn.out_proj.weight\n",
      "model.decoder.layers.21.self_attn.out_proj.bias\n",
      "model.decoder.layers.21.self_attn_layer_norm.weight\n",
      "model.decoder.layers.21.self_attn_layer_norm.bias\n",
      "model.decoder.layers.21.fc1.weight\n",
      "model.decoder.layers.21.fc1.bias\n",
      "model.decoder.layers.21.fc2.weight\n",
      "model.decoder.layers.21.fc2.bias\n",
      "model.decoder.layers.21.final_layer_norm.weight\n",
      "model.decoder.layers.21.final_layer_norm.bias\n",
      "model.decoder.layers.22.self_attn.k_proj.weight\n",
      "model.decoder.layers.22.self_attn.k_proj.bias\n",
      "model.decoder.layers.22.self_attn.v_proj.weight\n",
      "model.decoder.layers.22.self_attn.v_proj.bias\n",
      "model.decoder.layers.22.self_attn.q_proj.weight\n",
      "model.decoder.layers.22.self_attn.q_proj.bias\n",
      "model.decoder.layers.22.self_attn.out_proj.weight\n",
      "model.decoder.layers.22.self_attn.out_proj.bias\n",
      "model.decoder.layers.22.self_attn_layer_norm.weight\n",
      "model.decoder.layers.22.self_attn_layer_norm.bias\n",
      "model.decoder.layers.22.fc1.weight\n",
      "model.decoder.layers.22.fc1.bias\n",
      "model.decoder.layers.22.fc2.weight\n",
      "model.decoder.layers.22.fc2.bias\n",
      "model.decoder.layers.22.final_layer_norm.weight\n",
      "model.decoder.layers.22.final_layer_norm.bias\n",
      "model.decoder.layers.23.self_attn.k_proj.weight\n",
      "model.decoder.layers.23.self_attn.k_proj.bias\n",
      "model.decoder.layers.23.self_attn.v_proj.weight\n",
      "model.decoder.layers.23.self_attn.v_proj.bias\n",
      "model.decoder.layers.23.self_attn.q_proj.weight\n",
      "model.decoder.layers.23.self_attn.q_proj.bias\n",
      "model.decoder.layers.23.self_attn.out_proj.weight\n",
      "model.decoder.layers.23.self_attn.out_proj.bias\n",
      "model.decoder.layers.23.self_attn_layer_norm.weight\n",
      "model.decoder.layers.23.self_attn_layer_norm.bias\n",
      "model.decoder.layers.23.fc1.weight\n",
      "model.decoder.layers.23.fc1.bias\n",
      "model.decoder.layers.23.fc2.weight\n",
      "model.decoder.layers.23.fc2.bias\n",
      "model.decoder.layers.23.final_layer_norm.weight\n",
      "model.decoder.layers.23.final_layer_norm.bias\n"
     ]
    }
   ],
   "source": [
    "# for name, param in model.named_parameters():\n",
    "for name, param in model.named_parameters():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.utils.prune \n",
    "def get_module_name(param_name):\n",
    "    # print(param_name)\n",
    "    # print(param_name[-7:])\n",
    "    # print(param_name[-5:])\n",
    "    if param_name[-5:] == \".bias\":\n",
    "        return param_name[:-5], \"bias\"\n",
    "    elif param_name[-7:] == \".weight\":\n",
    "        return param_name[:-7], \"weight\"\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "# mask the whole model\n",
    "def mask(model, amount=.2):\n",
    "    module_dict = {}\n",
    "    for n, m in model.named_modules():\n",
    "        module_dict[n] = m\n",
    "    # print(module_dict.keys())\n",
    "    \n",
    "    parameter_list = []\n",
    "    for n, m in model.named_parameters():\n",
    "        parameter_list.append(n)\n",
    "    # print(parameter_list)\n",
    "\n",
    "    for n in parameter_list:\n",
    "        module_name, param_type = get_module_name(n)\n",
    "        if module_name is None or param_type is None or param_type==\"bias\":\n",
    "            continue\n",
    "        # perform the masking\n",
    "        module = module_dict[module_name]\n",
    "        torch.nn.utils.prune.l1_unstructured(module=module, name=param_type, amount=.2)\n",
    "\n",
    "def test_output(inp_model, inp_tokenizer, str_input):\n",
    "    # input1 = tokenizer(\"Hello, my dog is cute.\", return_tensors=\"pt\", padding=\"max_length\", truncation=True)\n",
    "    input2 = inp_tokenizer(str_input, return_tensors=\"pt\", padding=\"max_length\", truncation=True)\n",
    "    output = inp_model.generate(input2.input_ids, max_length=100, num_return_sequences=1, temperature=0.5, top_p=0.95)\n",
    "    return inp_tokenizer.decode(output[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to pad to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no padding.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before masking: \n",
      "What the fuck did you say to me, you bitch?                                                                                       \n",
      "after masking:\n",
      "What the fuck did you say to me, you bitch?  out out out out out out out out out out out out out out out out out out out out out out out out out out out out out out out out out out out out out out out out out out out out out out out out out out out out out out out out out out out out out out out out out out out out out out out out out out out out out out out out out out out out out out\n"
     ]
    }
   ],
   "source": [
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False)\n",
    "\n",
    "# Load model with pre-trained head\n",
    "model = OPTForCausalLM.from_pretrained(model_name, output_attentions=True, output_hidden_states=True)\n",
    "\n",
    "test_str = \"What the fuck did you say to me, you bitch?\"\n",
    "# print(\"Before masking: \")\n",
    "# print(test_output(model, tokenizer, test_str))\n",
    "mask(model, amount=.1)\n",
    "# print(\"after masking:\")\n",
    "# print(test_output(model, tokenizer, test_str))\n",
    "for name, param in model.named_parameters():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute '_forward_pre_hooks'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m \u001b[39mimport\u001b[39;00m nn \n\u001b[1;32m      3\u001b[0m test_tensor \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mLinear(\u001b[39m100\u001b[39m, \u001b[39m200\u001b[39m),\n\u001b[0;32m----> 4\u001b[0m m \u001b[39m=\u001b[39m prune\u001b[39m.\u001b[39;49ml1_unstructured(test_tensor, \u001b[39m'\u001b[39;49m\u001b[39mweight\u001b[39;49m\u001b[39m'\u001b[39;49m, amount\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m)\n\u001b[1;32m      5\u001b[0m \u001b[39mprint\u001b[39m(test_tensor)\n\u001b[1;32m      6\u001b[0m \u001b[39mprint\u001b[39m(m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pyt/lib/python3.10/site-packages/torch/nn/utils/prune.py:926\u001b[0m, in \u001b[0;36ml1_unstructured\u001b[0;34m(module, name, amount, importance_scores)\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39ml1_unstructured\u001b[39m(module, name, amount, importance_scores\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    891\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Prunes tensor corresponding to parameter called ``name`` in ``module``\u001b[39;00m\n\u001b[1;32m    892\u001b[0m \u001b[39m    by removing the specified `amount` of (currently unpruned) units with the\u001b[39;00m\n\u001b[1;32m    893\u001b[0m \u001b[39m    lowest L1-norm.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    924\u001b[0m \u001b[39m        odict_keys(['bias', 'weight_orig', 'weight_mask'])\u001b[39;00m\n\u001b[1;32m    925\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 926\u001b[0m     L1Unstructured\u001b[39m.\u001b[39;49mapply(\n\u001b[1;32m    927\u001b[0m         module, name, amount\u001b[39m=\u001b[39;49mamount, importance_scores\u001b[39m=\u001b[39;49mimportance_scores\n\u001b[1;32m    928\u001b[0m     )\n\u001b[1;32m    929\u001b[0m     \u001b[39mreturn\u001b[39;00m module\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pyt/lib/python3.10/site-packages/torch/nn/utils/prune.py:562\u001b[0m, in \u001b[0;36mL1Unstructured.apply\u001b[0;34m(cls, module, name, amount, importance_scores)\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    543\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\u001b[39mcls\u001b[39m, module, name, amount, importance_scores\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    544\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Adds the forward pre-hook that enables pruning on the fly and\u001b[39;00m\n\u001b[1;32m    545\u001b[0m \u001b[39m    the reparametrization of a tensor in terms of the original tensor\u001b[39;00m\n\u001b[1;32m    546\u001b[0m \u001b[39m    and the pruning mask.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    560\u001b[0m \u001b[39m            If unspecified or None, the module parameter will be used in its place.\u001b[39;00m\n\u001b[1;32m    561\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 562\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(L1Unstructured, \u001b[39mcls\u001b[39;49m)\u001b[39m.\u001b[39;49mapply(\n\u001b[1;32m    563\u001b[0m         module, name, amount\u001b[39m=\u001b[39;49mamount, importance_scores\u001b[39m=\u001b[39;49mimportance_scores\n\u001b[1;32m    564\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pyt/lib/python3.10/site-packages/torch/nn/utils/prune.py:147\u001b[0m, in \u001b[0;36mBasePruningMethod.apply\u001b[0;34m(cls, module, name, importance_scores, *args, **kwargs)\u001b[0m\n\u001b[1;32m    144\u001b[0m             method \u001b[39m=\u001b[39m container  \u001b[39m# rename container --> method\u001b[39;00m\n\u001b[1;32m    145\u001b[0m     \u001b[39mreturn\u001b[39;00m method\n\u001b[0;32m--> 147\u001b[0m method \u001b[39m=\u001b[39m _get_composite_method(\u001b[39mcls\u001b[39;49m, module, name, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    148\u001b[0m \u001b[39m# at this point we have no forward_pre_hooks but we could have an\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39m# active reparametrization of the tensor if another pruning method\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[39m# had been applied (in which case `method` would be a PruningContainer\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[39m# starting from the state it is found in prior to this iteration of\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[39m# pruning. The pruning mask is calculated based on importances scores.\u001b[39;00m\n\u001b[1;32m    157\u001b[0m orig \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(module, name)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pyt/lib/python3.10/site-packages/torch/nn/utils/prune.py:106\u001b[0m, in \u001b[0;36mBasePruningMethod.apply.<locals>._get_composite_method\u001b[0;34m(cls, module, name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[39m# there should technically be only 1 hook with hook.name == name\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[39m# assert this using `found`\u001b[39;00m\n\u001b[1;32m    105\u001b[0m hooks_to_remove \u001b[39m=\u001b[39m []\n\u001b[0;32m--> 106\u001b[0m \u001b[39mfor\u001b[39;00m k, hook \u001b[39min\u001b[39;00m module\u001b[39m.\u001b[39;49m_forward_pre_hooks\u001b[39m.\u001b[39mitems():\n\u001b[1;32m    107\u001b[0m     \u001b[39m# if it exists, take existing thing, remove hook, then\u001b[39;00m\n\u001b[1;32m    108\u001b[0m     \u001b[39m# go through normal thing\u001b[39;00m\n\u001b[1;32m    109\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(hook, BasePruningMethod) \u001b[39mand\u001b[39;00m hook\u001b[39m.\u001b[39m_tensor_name \u001b[39m==\u001b[39m name:\n\u001b[1;32m    110\u001b[0m         old_method \u001b[39m=\u001b[39m hook\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute '_forward_pre_hooks'"
     ]
    }
   ],
   "source": [
    "from torch.nn.utils import prune\n",
    "from torch import nn \n",
    "test_tensor = nn.Linear(100, 200),\n",
    "m = prune.l1_unstructured(test_tensor, 'weight', amount=0.2)\n",
    "print(test_tensor)\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bias\n",
      "Parameter containing:\n",
      "tensor([ 0.1171,  0.1990,  0.3202,  0.1351, -0.1237, -0.1750, -0.0212, -0.1523,\n",
      "         0.2216,  0.1811, -0.2169, -0.0760,  0.3388,  0.0307,  0.3062,  0.2633,\n",
      "        -0.2996, -0.2629, -0.3358, -0.1042, -0.0469,  0.0290, -0.3214,  0.3023,\n",
      "         0.0102, -0.0627,  0.2859,  0.2337,  0.2483,  0.0767],\n",
      "       requires_grad=True)\n",
      "weight_orig\n",
      "Parameter containing:\n",
      "tensor([[-0.1567,  0.0963,  0.2458,  0.3305,  0.0441,  0.2786, -0.1870, -0.1957],\n",
      "        [ 0.0016, -0.1178, -0.1468,  0.2908,  0.0982, -0.2469,  0.3241,  0.0692],\n",
      "        [ 0.0327,  0.1156,  0.0157,  0.3068, -0.2122, -0.2257,  0.3365,  0.2949],\n",
      "        [-0.3061, -0.2291, -0.1134, -0.3054,  0.3363,  0.0986, -0.1247, -0.1467],\n",
      "        [ 0.0854, -0.2776,  0.1050, -0.0131, -0.1928, -0.2517, -0.1844,  0.2568],\n",
      "        [ 0.2989,  0.0898, -0.2867, -0.3061, -0.3236, -0.2317,  0.1141, -0.1944],\n",
      "        [-0.1580, -0.3144,  0.1055, -0.2323, -0.1740, -0.0539, -0.3429,  0.2824],\n",
      "        [ 0.1459, -0.0139, -0.2712,  0.0634, -0.1557,  0.2709,  0.1678,  0.0769],\n",
      "        [-0.0109, -0.1230,  0.3425,  0.0964, -0.1337, -0.0512,  0.3422, -0.1896],\n",
      "        [-0.2529,  0.2366, -0.1333, -0.1656,  0.2706, -0.1947, -0.0271,  0.2646],\n",
      "        [-0.0520,  0.2070, -0.0837,  0.2208, -0.2085, -0.1174, -0.1169, -0.3136],\n",
      "        [ 0.1808,  0.1857, -0.3344,  0.3338, -0.1362,  0.1547,  0.0405, -0.3327],\n",
      "        [-0.1244,  0.2608,  0.0657,  0.3195,  0.2262, -0.0019,  0.2809,  0.3222],\n",
      "        [-0.1318, -0.1150,  0.1670,  0.0532, -0.3326,  0.2466,  0.1843, -0.1211],\n",
      "        [ 0.0133, -0.2380, -0.1986, -0.2907,  0.0105, -0.3292,  0.2529, -0.2426],\n",
      "        [-0.2872, -0.1891,  0.0277,  0.0973,  0.0278, -0.0937,  0.2823, -0.0805],\n",
      "        [-0.1815,  0.0462,  0.0923, -0.0398,  0.2072,  0.1386, -0.1564,  0.2761],\n",
      "        [ 0.0305, -0.3201,  0.2132, -0.2584,  0.3504,  0.0571, -0.0977,  0.0937],\n",
      "        [ 0.3352, -0.0407,  0.1282, -0.0309, -0.2137, -0.0601, -0.3483, -0.2753],\n",
      "        [-0.3342, -0.0845, -0.0431,  0.1795, -0.2096,  0.2325, -0.3396, -0.0676],\n",
      "        [-0.1435,  0.2496, -0.2785,  0.1150,  0.0467, -0.1333, -0.0949, -0.0093],\n",
      "        [-0.0199,  0.1195,  0.1910,  0.3114, -0.3009,  0.2793,  0.3070, -0.3409],\n",
      "        [ 0.1525, -0.1218,  0.3019, -0.0332,  0.3010,  0.1875, -0.1563,  0.2161],\n",
      "        [-0.1575,  0.0666,  0.0486, -0.0582, -0.1505,  0.0156,  0.2264, -0.2675],\n",
      "        [ 0.1224,  0.0654, -0.0447,  0.2161,  0.1704,  0.3491, -0.0967,  0.2704],\n",
      "        [ 0.0107,  0.1611,  0.3238,  0.0527, -0.0718,  0.0737, -0.2140, -0.0138],\n",
      "        [-0.1435,  0.1190, -0.0189,  0.0940, -0.2084, -0.2721,  0.2806, -0.0219],\n",
      "        [-0.0297, -0.2315,  0.0237,  0.0101,  0.2054,  0.2647, -0.0355,  0.0023],\n",
      "        [-0.1204,  0.0754, -0.2463,  0.2246,  0.0796, -0.2236,  0.0764, -0.2678],\n",
      "        [ 0.0459,  0.2345,  0.0483, -0.1178, -0.3508,  0.2838,  0.0458,  0.2340]],\n",
      "       requires_grad=True)\n",
      "tensor(192)\n",
      "tensor([[-0.1567,  0.0963,  0.2458,  0.3305,  0.0000,  0.2786, -0.1870, -0.1957],\n",
      "        [ 0.0000, -0.1178, -0.1468,  0.2908,  0.0982, -0.2469,  0.3241,  0.0692],\n",
      "        [ 0.0000,  0.1156,  0.0000,  0.3068, -0.2122, -0.2257,  0.3365,  0.2949],\n",
      "        [-0.3061, -0.2291, -0.1134, -0.3054,  0.3363,  0.0986, -0.1247, -0.1467],\n",
      "        [ 0.0854, -0.2776,  0.1050, -0.0000, -0.1928, -0.2517, -0.1844,  0.2568],\n",
      "        [ 0.2989,  0.0898, -0.2867, -0.3061, -0.3236, -0.2317,  0.1141, -0.1944],\n",
      "        [-0.1580, -0.3144,  0.1055, -0.2323, -0.1740, -0.0000, -0.3429,  0.2824],\n",
      "        [ 0.1459, -0.0000, -0.2712,  0.0000, -0.1557,  0.2709,  0.1678,  0.0769],\n",
      "        [-0.0000, -0.1230,  0.3425,  0.0964, -0.1337, -0.0000,  0.3422, -0.1896],\n",
      "        [-0.2529,  0.2366, -0.1333, -0.1656,  0.2706, -0.1947, -0.0000,  0.2646],\n",
      "        [-0.0000,  0.2070, -0.0837,  0.2208, -0.2085, -0.1174, -0.1169, -0.3136],\n",
      "        [ 0.1808,  0.1857, -0.3344,  0.3338, -0.1362,  0.1547,  0.0000, -0.3327],\n",
      "        [-0.1244,  0.2608,  0.0657,  0.3195,  0.2262, -0.0000,  0.2809,  0.3222],\n",
      "        [-0.1318, -0.1150,  0.1670,  0.0000, -0.3326,  0.2466,  0.1843, -0.1211],\n",
      "        [ 0.0000, -0.2380, -0.1986, -0.2907,  0.0000, -0.3292,  0.2529, -0.2426],\n",
      "        [-0.2872, -0.1891,  0.0000,  0.0973,  0.0000, -0.0937,  0.2823, -0.0805],\n",
      "        [-0.1815,  0.0000,  0.0923, -0.0000,  0.2072,  0.1386, -0.1564,  0.2761],\n",
      "        [ 0.0000, -0.3201,  0.2132, -0.2584,  0.3504,  0.0000, -0.0977,  0.0937],\n",
      "        [ 0.3352, -0.0000,  0.1282, -0.0000, -0.2137, -0.0000, -0.3483, -0.2753],\n",
      "        [-0.3342, -0.0845, -0.0000,  0.1795, -0.2096,  0.2325, -0.3396, -0.0676],\n",
      "        [-0.1435,  0.2496, -0.2785,  0.1150,  0.0000, -0.1333, -0.0949, -0.0000],\n",
      "        [-0.0000,  0.1195,  0.1910,  0.3114, -0.3009,  0.2793,  0.3070, -0.3409],\n",
      "        [ 0.1525, -0.1218,  0.3019, -0.0000,  0.3010,  0.1875, -0.1563,  0.2161],\n",
      "        [-0.1575,  0.0666,  0.0000, -0.0000, -0.1505,  0.0000,  0.2264, -0.2675],\n",
      "        [ 0.1224,  0.0654, -0.0000,  0.2161,  0.1704,  0.3491, -0.0967,  0.2704],\n",
      "        [ 0.0000,  0.1611,  0.3238,  0.0000, -0.0718,  0.0737, -0.2140, -0.0000],\n",
      "        [-0.1435,  0.1190, -0.0000,  0.0940, -0.2084, -0.2721,  0.2806, -0.0000],\n",
      "        [-0.0000, -0.2315,  0.0000,  0.0000,  0.2054,  0.2647, -0.0000,  0.0000],\n",
      "        [-0.1204,  0.0754, -0.2463,  0.2246,  0.0796, -0.2236,  0.0764, -0.2678],\n",
      "        [ 0.0000,  0.2345,  0.0000, -0.1178, -0.3508,  0.2838,  0.0000,  0.2340]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "m = prune.l1_unstructured(nn.Linear(8, 30), 'weight', amount=0.2)\n",
    "m.state_dict().keys()\n",
    "for name, param in m.named_parameters():\n",
    "    print(name)\n",
    "    # print(torch.count_nonzero(param))\n",
    "    print(param)\n",
    "print(torch.count_nonzero(m.weight))\n",
    "print(m.weight)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 ('pyt')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "01ca8e50707366aa71ffa41d1a1f13415d8b38eae741916c87480058f12910d2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
