{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.utils import prune\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from transformers import AutoTokenizer, OPTForCausalLM, pipeline\n",
    "from datasets import load_dataset\n",
    "\n",
    "from calculate_mask import calculate_mask\n",
    "from inverse_hessian import calc_inverse_hessian\n",
    "from input_prehooks import put_input_hooks\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# run model on batches of calibration data, then concatenate inputs\n",
    "def split_model_calibration(model):\n",
    "    batch_sentences = []\n",
    "    for i, data in tqdm(enumerate(iter(dataset['train'])), total=calibration_size):\n",
    "        if i < calibration_size + 1:\n",
    "            if len(batch_sentences) >= calibration_batch_size:\n",
    "                with torch.no_grad():\n",
    "                    encoded_input = tokenizer(batch_sentences, return_tensors=\"pt\",\n",
    "                                              padding=\"max_length\", max_length=token_length,\n",
    "                                              truncation=True).to(device=device)\n",
    "                    model(**encoded_input, labels=encoded_input.input_ids)\n",
    "                    torch.cuda.empty_cache()\n",
    "                    batch_sentences = []\n",
    "            batch_sentences.append(data['text'])\n",
    "        else:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparsify and Finetune Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_size=128\n",
    "token_length=1024\n",
    "calibration_batch_size=1\n",
    "\n",
    "EPSILON = 1e-8\n",
    "B = 128\n",
    "Bs = 128\n",
    "\n",
    "#hyperparam test, remove later\n",
    "EPOCH_COUNT = 10\n",
    "\n",
    "#set device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu' \n",
    "model_name = \"opt-2.7b\"\n",
    "#load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(f'facebook/{model_name}')\n",
    "#Load dataset\n",
    "dataset = load_dataset('c4', 'en', streaming=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]\n",
      "  0%|          | 0/128 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|          | 1/128 [00:00<00:25,  5.01it/s]\u001b[A/gs/gsfs0/users/asyed/.local/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "\n",
      "  2%|▏         | 2/128 [00:04<05:21,  2.55s/it]\u001b[A\n",
      "  2%|▏         | 3/128 [00:09<07:31,  3.61s/it]\u001b[A\n",
      "  3%|▎         | 4/128 [00:14<08:28,  4.10s/it]\u001b[A\n",
      "  4%|▍         | 5/128 [00:18<08:58,  4.38s/it]\u001b[A\n",
      "  5%|▍         | 6/128 [00:23<09:14,  4.55s/it]\u001b[A\n",
      "  5%|▌         | 7/128 [00:28<09:22,  4.65s/it]\u001b[A\n",
      "  6%|▋         | 8/128 [00:33<09:25,  4.72s/it]\u001b[A\n",
      "  7%|▋         | 9/128 [00:38<09:26,  4.76s/it]\u001b[A\n",
      "  8%|▊         | 10/128 [00:43<09:25,  4.79s/it]\u001b[A\n",
      "  9%|▊         | 11/128 [00:48<09:23,  4.82s/it]\u001b[A\n",
      "  9%|▉         | 12/128 [00:53<09:20,  4.83s/it]\u001b[A\n",
      " 10%|█         | 13/128 [00:57<09:16,  4.84s/it]\u001b[A\n",
      " 11%|█         | 14/128 [01:02<09:12,  4.85s/it]\u001b[A\n",
      " 12%|█▏        | 15/128 [01:07<09:08,  4.85s/it]\u001b[A\n",
      " 12%|█▎        | 16/128 [01:12<09:03,  4.86s/it]\u001b[A\n",
      " 13%|█▎        | 17/128 [01:17<09:00,  4.87s/it]\u001b[A\n",
      " 14%|█▍        | 18/128 [01:22<08:55,  4.87s/it]\u001b[A\n",
      " 15%|█▍        | 19/128 [01:27<08:50,  4.87s/it]\u001b[A\n",
      " 16%|█▌        | 20/128 [01:31<08:45,  4.87s/it]\u001b[A\n",
      " 16%|█▋        | 21/128 [01:36<08:41,  4.87s/it]\u001b[A\n",
      " 17%|█▋        | 22/128 [01:41<08:36,  4.87s/it]\u001b[A\n",
      " 18%|█▊        | 23/128 [01:46<08:31,  4.87s/it]\u001b[A\n",
      " 19%|█▉        | 24/128 [01:51<08:26,  4.87s/it]\u001b[A\n",
      " 20%|█▉        | 25/128 [01:56<08:21,  4.87s/it]\u001b[A\n",
      " 20%|██        | 26/128 [02:01<08:16,  4.86s/it]\u001b[A\n",
      " 21%|██        | 27/128 [02:06<08:11,  4.87s/it]\u001b[A\n",
      " 22%|██▏       | 28/128 [02:10<08:06,  4.87s/it]\u001b[A\n",
      " 23%|██▎       | 29/128 [02:15<08:01,  4.87s/it]\u001b[A\n",
      " 23%|██▎       | 30/128 [02:20<07:57,  4.87s/it]\u001b[A\n",
      " 24%|██▍       | 31/128 [02:25<07:51,  4.87s/it]\u001b[A\n",
      " 25%|██▌       | 32/128 [02:30<07:47,  4.87s/it]\u001b[A\n",
      " 26%|██▌       | 33/128 [02:35<07:42,  4.87s/it]\u001b[A\n",
      " 27%|██▋       | 34/128 [02:40<07:37,  4.87s/it]\u001b[A\n",
      " 27%|██▋       | 35/128 [02:45<07:32,  4.87s/it]\u001b[A\n",
      " 28%|██▊       | 36/128 [02:49<07:28,  4.87s/it]\u001b[A\n",
      " 29%|██▉       | 37/128 [02:54<07:22,  4.87s/it]\u001b[A\n",
      " 30%|██▉       | 38/128 [02:59<07:18,  4.87s/it]\u001b[A\n",
      " 30%|███       | 39/128 [03:04<07:13,  4.87s/it]\u001b[A\n",
      " 31%|███▏      | 40/128 [03:09<07:08,  4.87s/it]\u001b[A\n",
      " 32%|███▏      | 41/128 [03:14<07:03,  4.87s/it]\u001b[A\n",
      " 33%|███▎      | 42/128 [03:19<06:58,  4.87s/it]\u001b[A\n",
      " 34%|███▎      | 43/128 [03:23<06:53,  4.87s/it]\u001b[A\n",
      " 34%|███▍      | 44/128 [03:28<06:48,  4.87s/it]\u001b[A\n",
      " 35%|███▌      | 45/128 [03:33<06:43,  4.87s/it]\u001b[A\n",
      " 36%|███▌      | 46/128 [03:38<06:39,  4.87s/it]\u001b[A\n",
      " 37%|███▋      | 47/128 [03:43<06:34,  4.87s/it]\u001b[A\n",
      " 38%|███▊      | 48/128 [03:48<06:29,  4.87s/it]\u001b[A\n",
      " 38%|███▊      | 49/128 [03:53<06:24,  4.87s/it]\u001b[A\n",
      " 39%|███▉      | 50/128 [03:58<06:19,  4.87s/it]\u001b[A\n",
      " 40%|███▉      | 51/128 [04:02<06:14,  4.87s/it]\u001b[A\n",
      " 41%|████      | 52/128 [04:07<06:10,  4.87s/it]\u001b[A\n",
      " 41%|████▏     | 53/128 [04:12<06:05,  4.87s/it]\u001b[A\n",
      " 42%|████▏     | 54/128 [04:17<06:00,  4.87s/it]\u001b[A\n",
      " 43%|████▎     | 55/128 [04:22<05:55,  4.87s/it]\u001b[A\n",
      " 44%|████▍     | 56/128 [04:27<05:50,  4.87s/it]\u001b[A\n",
      " 45%|████▍     | 57/128 [04:32<05:45,  4.86s/it]\u001b[A\n",
      " 45%|████▌     | 58/128 [04:36<05:40,  4.87s/it]\u001b[A\n",
      " 46%|████▌     | 59/128 [04:41<05:36,  4.87s/it]\u001b[A\n",
      " 47%|████▋     | 60/128 [04:46<05:31,  4.88s/it]\u001b[A\n",
      " 48%|████▊     | 61/128 [04:51<05:26,  4.88s/it]\u001b[A\n",
      " 48%|████▊     | 62/128 [04:56<05:21,  4.88s/it]\u001b[A\n",
      " 49%|████▉     | 63/128 [05:01<05:16,  4.87s/it]\u001b[A\n",
      " 50%|█████     | 64/128 [05:06<05:11,  4.87s/it]\u001b[A\n",
      " 51%|█████     | 65/128 [05:11<05:07,  4.88s/it]\u001b[A\n",
      " 52%|█████▏    | 66/128 [05:15<05:02,  4.87s/it]\u001b[A\n",
      " 52%|█████▏    | 67/128 [05:20<04:57,  4.87s/it]\u001b[A\n",
      " 53%|█████▎    | 68/128 [05:25<04:52,  4.87s/it]\u001b[A\n",
      " 54%|█████▍    | 69/128 [05:30<04:47,  4.87s/it]\u001b[A\n",
      " 55%|█████▍    | 70/128 [05:35<04:42,  4.87s/it]\u001b[A\n",
      " 55%|█████▌    | 71/128 [05:40<04:37,  4.87s/it]\u001b[A\n",
      " 56%|█████▋    | 72/128 [05:45<04:32,  4.87s/it]\u001b[A\n",
      " 57%|█████▋    | 73/128 [05:50<04:28,  4.87s/it]\u001b[A\n",
      " 58%|█████▊    | 74/128 [05:54<04:23,  4.87s/it]\u001b[A\n",
      " 59%|█████▊    | 75/128 [05:59<04:18,  4.87s/it]\u001b[A\n",
      " 59%|█████▉    | 76/128 [06:04<04:13,  4.87s/it]\u001b[A\n",
      " 60%|██████    | 77/128 [06:09<04:08,  4.87s/it]\u001b[A\n",
      " 61%|██████    | 78/128 [06:14<04:03,  4.87s/it]\u001b[A\n",
      " 62%|██████▏   | 79/128 [06:19<03:58,  4.87s/it]\u001b[A\n",
      " 62%|██████▎   | 80/128 [06:24<03:53,  4.87s/it]\u001b[A\n",
      " 63%|██████▎   | 81/128 [06:29<03:48,  4.87s/it]\u001b[A\n",
      " 64%|██████▍   | 82/128 [06:33<03:43,  4.87s/it]\u001b[A\n",
      " 65%|██████▍   | 83/128 [06:38<03:39,  4.87s/it]\u001b[A\n",
      " 66%|██████▌   | 84/128 [06:43<03:35,  4.89s/it]\u001b[A\n",
      " 66%|██████▋   | 85/128 [06:49<03:36,  5.03s/it]\u001b[A\n",
      " 67%|██████▋   | 86/128 [06:54<03:33,  5.07s/it]\u001b[A\n",
      " 68%|██████▊   | 87/128 [06:59<03:26,  5.04s/it]\u001b[A\n",
      " 69%|██████▉   | 88/128 [07:04<03:21,  5.04s/it]\u001b[A\n",
      " 70%|██████▉   | 89/128 [07:09<03:15,  5.01s/it]\u001b[A\n",
      " 70%|███████   | 90/128 [07:14<03:08,  4.97s/it]\u001b[A\n",
      " 71%|███████   | 91/128 [07:18<03:02,  4.94s/it]\u001b[A\n",
      " 72%|███████▏  | 92/128 [07:23<02:57,  4.92s/it]\u001b[A\n",
      " 73%|███████▎  | 93/128 [07:28<02:51,  4.91s/it]\u001b[A\n",
      " 73%|███████▎  | 94/128 [07:33<02:46,  4.90s/it]\u001b[A\n",
      " 74%|███████▍  | 95/128 [07:38<02:41,  4.89s/it]\u001b[A\n",
      " 75%|███████▌  | 96/128 [07:43<02:36,  4.89s/it]\u001b[A\n",
      " 76%|███████▌  | 97/128 [07:48<02:31,  4.89s/it]\u001b[A\n",
      " 77%|███████▋  | 98/128 [07:53<02:26,  4.88s/it]\u001b[A\n",
      " 77%|███████▋  | 99/128 [07:57<02:21,  4.88s/it]\u001b[A\n",
      " 78%|███████▊  | 100/128 [08:02<02:16,  4.87s/it]\u001b[A\n",
      " 79%|███████▉  | 101/128 [08:07<02:11,  4.87s/it]\u001b[A\n",
      " 80%|███████▉  | 102/128 [08:12<02:06,  4.87s/it]\u001b[A\n",
      " 80%|████████  | 103/128 [08:17<02:01,  4.87s/it]\u001b[A\n",
      " 81%|████████▏ | 104/128 [08:22<01:56,  4.87s/it]\u001b[A\n",
      " 82%|████████▏ | 105/128 [08:27<01:51,  4.87s/it]\u001b[A\n",
      " 83%|████████▎ | 106/128 [08:32<01:47,  4.87s/it]\u001b[A"
     ]
    }
   ],
   "source": [
    "from testing_module import finetune_model\n",
    "from iterative_prune_finetune import iterative_sparsegpt_prune_tune\n",
    "SPARSITIES = [0.2,0.3,0.5,0.7,0.9,1]#0.1, 0.2,0.3,0.5,0.7,0.9,1\n",
    "#encode tokens\n",
    "\n",
    "    \n",
    "for i, SPARSITY in enumerate(tqdm(SPARSITIES, total=len(SPARSITIES))):\n",
    "    # Load model with pre-trained head\n",
    "    model = OPTForCausalLM.from_pretrained(f'facebook/{model_name}', output_attentions=True,\n",
    "                                           output_hidden_states=True).to(device=device) # type: ignore\n",
    "    model = torch.nn.DataParallel(model, device_ids=[0,1,2,3])\n",
    "    \n",
    "    if i == 0:\n",
    "        feature_hessians = {}\n",
    "        #put_input_hooks(model=model, features=feature_hessians, storage_dir=storage_dir, offload_freq=10000, feature_storage_device='cpu')\n",
    "        put_input_hooks(model=model, features=feature_hessians, feature_storage_device='cpu')\n",
    "        split_model_calibration(model)\n",
    "    torch.cuda.empty_cache()\n",
    "    iterative_sparsegpt_prune_tune(model=model, model_size=model_name,\n",
    "                                   sparseness_sequence=[SPARSITY],\n",
    "                                   feature_hessians=feature_hessians,\n",
    "                                   EPSILON=EPSILON, B=B, Bs=Bs,\n",
    "                                   tokenizer=tokenizer,\n",
    "                                   EPOCH_COUNT=EPOCH_COUNT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "import numpy as np\n",
    "from testing_module import test_model\n",
    "\n",
    "model_name = \"opt-350m\"\n",
    "token_length=1024\n",
    "stride = 512\n",
    "wandb.init(project=\"ICLR\", \n",
    "           name = f'{model_name} Wikitext Test', \n",
    "           config={'token_length': token_length,\n",
    "                 'model_name': model_name,\n",
    "                 'stride': stride,\n",
    "                 'fine_tuned': 'not finetuned'})\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(f'facebook/{model_name}', \n",
    "                                          padding_side='left', \n",
    "                                          use_fast=False)\n",
    "# Load dataset\n",
    "test_set = load_dataset('wikitext', 'wikitext-2-raw-v1', split='test')\n",
    "encodings = tokenizer(\"\\n\\n\".join(test_set['text']), return_tensors='pt')\n",
    "\n",
    "seq_len = encodings.input_ids.size(1)\n",
    "SPARSITIES = [0.2, 0.3, 0.5, 0.7, 0.9, 1]#, 0.4, 0.6, 0.8, 1\n",
    "\n",
    "for SPARSITY in SPARSITIES:\n",
    "    test_model(model_name, encodings, token_length, seq_len, stride, wandb, SPARSITY, is_finetuned=False)\n",
    "    \n",
    "### NOW DO FINETUNED\n",
    "wandb.init(project=\"ICLR\", \n",
    "           name = f'{model_name} Wikitext Test', \n",
    "           config={'token_length': token_length,\n",
    "                 'model_name': model_name,\n",
    "                 'stride': stride,\n",
    "                 'fine_tuned': 'finetuned'})\n",
    "for SPARSITY in SPARSITIES:\n",
    "    test_model(model_name, encodings, token_length, seq_len, stride, wandb, SPARSITY, is_finetuned=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iteratively Prune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from SparseGPT_pruning import sparsegpt_prune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sparsegpt_prune()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "01ca8e50707366aa71ffa41d1a1f13415d8b38eae741916c87480058f12910d2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
