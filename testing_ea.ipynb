{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook for testing Emergent Abilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/phillipguo/opt/anaconda3/envs/pyt/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn.utils import prune\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from transformers import AutoTokenizer, OPTForCausalLM, pipeline\n",
    "from datasets import load_dataset\n",
    "\n",
    "from calculate_mask import calculate_mask\n",
    "from inverse_hessian import calc_inverse_hessian\n",
    "from input_prehooks import put_input_hooks\n",
    "from testing_module import calculate_perp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 685/685 [00:00<00:00, 475kB/s]\n",
      "Downloading: 100%|██████████| 691/691 [00:00<00:00, 437kB/s]\n",
      "Downloading: 100%|██████████| 899k/899k [00:00<00:00, 7.28MB/s]\n",
      "Downloading: 100%|██████████| 456k/456k [00:00<00:00, 4.16MB/s]\n",
      "Downloading: 100%|██████████| 441/441 [00:00<00:00, 318kB/s]\n",
      "Downloading: 100%|██████████| 5.30G/5.30G [01:55<00:00, 45.9MB/s]\n"
     ]
    }
   ],
   "source": [
    "#DEVICE\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# model_name = \"facebook/opt-125m\"\n",
    "# model_name = \"facebook/opt-1.3b\"\n",
    "model_name = \"facebook/opt-2.7b\"\n",
    "\n",
    "#Load dataset\n",
    "dataset = load_dataset('c4', 'en', streaming=True)\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, padding_side='left', max_new_tokens=30, max_length=100)\n",
    "\n",
    "# Load model with pre-trained head\n",
    "# model = OPTForCausalLM.from_pretrained(model_name, output_attentions=True, output_hidden_states=True).to(device=device) # type: ignore\n",
    "\n",
    "# Load generator\n",
    "generator = pipeline('text-generation', model=model_name, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Hello, my name is John. I am a professional photographer and I am looking for a photographer to'}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator('Hello, my name is', temperature=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': '5 + 5 = 10, 13 + 16 = 29, 10 + 15 = 25, 10 +'}]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator('5 + 5 = 10, 13 + 16 = 29, 10 + 15 =', temperature=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# digit addition few shot generator\n",
    "import random\n",
    "def generate_addition_few_shot(num_dig, num_examples):\n",
    "    few_shot_str = \"\"\n",
    "    for ex in range(num_examples):\n",
    "        max_num = 10**num_dig-1\n",
    "        num1 = random.randint(1, max_num)\n",
    "        num2 = random.randint(1, max_num)\n",
    "        sum = num1+num2\n",
    "        few_shot_str += f'{num1} + {num2} = {sum}, '\n",
    "    return few_shot_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input length of input_ids is 66, but `max_length` is set to 21. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': '86 + 88 = 174, 96 + 61 = 157, 72 + 52 = 124, 21 + 45 = 66, 44 + 81 = 125, 51 + 49 = 100, 23 + 64 = 87, 63 + 36 = 99, 56 + 24 = 80, 89 + 31 = 120,  11 + 25 = 34'}]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_str = generate_addition_few_shot(2, 10) + \" 11 + 25 =\"\n",
    "generator(inp_str, temperature=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 ('pyt')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "01ca8e50707366aa71ffa41d1a1f13415d8b38eae741916c87480058f12910d2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
